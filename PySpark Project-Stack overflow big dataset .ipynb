{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "# Spark Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Stack Overflow is a collaboratively edited question-and-answer site originally focused on programming topics. Because of the variety of features tracked, including a variety of feedback metrics, it allows for some open-ended analysis of user behavior on the site.\n",
    "\n",
    "Stack Exchange (the parent organization) provides an anonymized [data dump](https://archive.org/details/stackexchange), and we'll use Spark to perform data manipulation, analysis, and machine learning on this data set. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Workflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Accessing the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "The data is available on S3 (`s3://dataincubator-course/spark-stack-data`). There are three sub-folders, `allUsers`, `allPosts`, and `allVotes`, which contain Gzipped XML with the following format:\n",
    "\n",
    "``` html\n",
    "<row Body=\"&lt;p&gt;I always validate my web pages, and I recommend you do the same BUT many large company websites DO NOT and cannot validate because the importance of the website looking exactly the same on all systems requires rules to be broken. &lt;/p&gt;&#10;&#10;&lt;p&gt;In general, valid websites help your page look good even on odd configurations (like cell phones) so you should always at least try to make it validate.&lt;/p&gt;&#10;\" CommentCount=\"0\" CreationDate=\"2008-10-12T20:26:29.397\" Id=\"195995\" LastActivityDate=\"2008-10-12T20:26:29.397\" OwnerDisplayName=\"Eric Wendelin\" OwnerUserId=\"25066\" ParentId=\"195973\" PostTypeId=\"2\" Score=\"0\" />\n",
    "```\n",
    "\n",
    "Data from the much smaller `stats.stackexchange.com` is available in the same format on S3 (`s3://dataincubator-course/spark-stats-data`). This site, Cross-Validated, will be used below in some instances to avoid working with the full data set for every question.\n",
    "\n",
    "The full schema is available as a text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://dataincubator-course/spark-stats-data/stack_exchange_schema.txt to ./stack_exchange_schema.txt\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://dataincubator-course/spark-stats-data/stack_exchange_schema.txt ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "I can either get the data by running the appropriate S3 commands in the terminal, or by running this block for the smaller stats data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "!mkdir -p spark-stats-data\n",
    "!aws s3 sync --exclude '*' --include 'all*' s3://dataincubator-course/spark-stats-data/ ./spark-stats-data\n",
    "!aws s3 sync --exclude '*' --include 'posts*zip' s3://dataincubator-course/spark-stats-data/ ./spark-stats-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "And to get the much larger full data set (be warned, this can take 20 or more minutes, so you may want to run it in the terminal to avoid locking up the notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "!mkdir -p spark-stack-data\n",
    "!aws s3 sync --exclude '*' --include 'all*' s3://dataincubator-course/spark-stack-data/ ./spark-stack-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Data input and parsing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Bad XML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "First, I want to create an RDD of Post objects where each Post is a valid row of XML from the Cross-Validated (stats.stackexchange.com) `allPosts` data set.\n",
    "\n",
    "I am are going to take several shortcuts to speed up and simplify our computations.  First, my parsing function should only attempt to parse rows that start with `<row` as these denote actual data entries. This should be done in Spark as the data is being read in from disk, without any pre-Spark processing. \n",
    "\n",
    "Return the total number of XML rows that started with `<row` that were subsequently **rejected** during your processing.  Note that the text is unicode, and contains non-ASCII characters.  We may need to re-encode to UTF-8 (depending on your XML parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-00000.xml.gz  part-00001.xml.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls spark-stats-data/allUsers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SQLContext\n",
    "\n",
    "sc = SparkContext(\"local[*]\", \"temp\")\n",
    "SQLContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'322'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = etree.parse('spark-stack-data/allPosts/part-00000.xml.gz')\n",
    "root = tree.getroot()\n",
    "firstrow = root.getchildren()[0]\n",
    "firstrow.get('Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_lines = sc.textFile('spark-stats-data/allPosts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "User_lines = sc.textFile('spark-stats-data/allUsers/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<?xml version=\"1.0\" encoding=\"UTF-8\"?>',\n",
       " '<parent>',\n",
       " '  <row AccountId=\"5872878\" CreationDate=\"2015-03-02T18:42:20.510\" DisplayName=\"Lars Reeker\" DownVotes=\"0\" Id=\"70185\" LastAccessDate=\"2015-03-02T18:42:20.510\" ProfileImageUrl=\"https://lh3.googleusercontent.com/-Y7GNsydm-mc/AAAAAAAAAAI/AAAAAAAADq8/15o5t99O5IU/photo.jpg\" Reputation=\"1\" UpVotes=\"0\" Views=\"0\" />',\n",
       " '  ',\n",
       " '  <row AccountId=\"5872995\" CreationDate=\"2015-03-02T19:04:13.380\" DisplayName=\"Vra\" DownVotes=\"0\" Id=\"70186\" LastAccessDate=\"2015-03-06T15:45:57.590\" Reputation=\"6\" UpVotes=\"0\" Views=\"1\" />',\n",
       " '  ',\n",
       " '  <row AboutMe=\"\" AccountId=\"5873177\" CreationDate=\"2015-03-02T19:40:16.420\" DisplayName=\"Aroona\" DownVotes=\"0\" Id=\"70187\" LastAccessDate=\"2015-03-02T19:40:16.420\" ProfileImageUrl=\"https://www.gravatar.com/avatar/e0e90702da3203e069f0a7d957ee7ea6?s=128&amp;d=identicon&amp;r=PG&amp;f=1\" Reputation=\"1\" UpVotes=\"0\" Views=\"0\" WebsiteUrl=\"\" />',\n",
       " '  ',\n",
       " '  <row AccountId=\"5873184\" CreationDate=\"2015-03-02T19:46:45.400\" DisplayName=\"Yazeed\" DownVotes=\"0\" Id=\"70188\" LastAccessDate=\"2015-03-02T19:46:45.400\" ProfileImageUrl=\"https://www.gravatar.com/avatar/f5e666cb769dfbc30e53bfe8a702dd38?s=128&amp;d=identicon&amp;r=PG&amp;f=1\" Reputation=\"1\" UpVotes=\"0\" Views=\"0\" />',\n",
       " '  ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "User_lines.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isRow(line):\n",
    "    return line.strip()[:4] == '<row'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isBadXML(s):\n",
    "    try:\n",
    "        etree.fromstring(s.strip())\n",
    "        return False\n",
    "    except Exception:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "781"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_lines.filter(isRow).filter(isBadXML).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<?xml version=\"1.0\" encoding=\"UTF-8\"?>',\n",
       " '<parent>',\n",
       " '  <row AnswerCount=\"0\" Body=\"&lt;p&gt;I\\'m developing an application in which users can create \\'sections\\' (Ã  la subreddit in reddit), in which items/posts can be created and voted with a thumbs-up/down system.&lt;/p&gt;&#10;&#10;&lt;p&gt;&lt;a href=&quot;http://www.evanmiller.org/how-not-to-sort-by-average-rating.html&quot; rel=&quot;nofollow&quot;&gt;A great article&lt;/a&gt; guided me on how to sort these votes so that an item with a 100% positive response but with few votes won\\'t get ranked over one with hundreds of votes and an acceptance of 80%. The article describes it pretty well.&lt;/p&gt;&#10;&#10;&lt;p&gt;However, I\\'d like to discard the lowest-ranked items and this is where it gets tricky:&lt;/p&gt;&#10;&#10;&lt;ul&gt;&#10;&lt;li&gt;How could I know the minimum number of votes in order to discard it?&lt;/li&gt;&#10;&lt;li&gt;What is the score\\'s threshold required to discard the item?&lt;/li&gt;&#10;&lt;/ul&gt;&#10;&#10;&lt;p&gt;As I said, there are sections, and each one has items (which are the ones voted). The formula has to take into consideration the fact that one section may have 100 items with thousands of votes and another might have 3 or 4 items with 20 votes, so a minimum of 40 votes required might be optimal for the first case but totally out of bounds for the second.&lt;/p&gt;&#10;&#10;&lt;p&gt;(I was tempted in posting this to MathOverflow, but I\\'m not really sure since this also involves some programming)&lt;/p&gt;&#10;&#10;&lt;p&gt;Thanks!&lt;/p&gt;&#10;\" CommentCount=\"0\" CreationDate=\"2011-05-16T17:39:58.170\" FavoriteCount=\"0\" Id=\"10893\" LastActivityDate=\"2011-06-02T22:10:16.550\" LastEditDate=\"2011-06-02T22:10:16.550\" LastEditorUserId=\"88\" OwnerDisplayName=\"metrobalderas\" OwnerUserId=\"4638\" PostTypeId=\"1\" Score=\"2\" Tags=\"&lt;confidence-interval&gt;\" Title=\"Formula to discard items by votes (Lower bound of Wilson score confidence interval)\" ViewCount=\"223\" />',\n",
       " '  ',\n",
       " '  <row Body=\"&lt;p&gt;Perhaps you could extend the idea of using the lower bound of the confidence interval for sorting: you could throw away items that have a low &lt;em&gt;upper&lt;/em&gt; bound. The items with only a few votes will have pretty high upper bounds; the lowest upper bounds will correspond to the lowest &quot;quality&quot; items.&lt;/p&gt;&#10;\" CommentCount=\"5\" CreationDate=\"2011-05-16T18:27:42.933\" Id=\"10894\" LastActivityDate=\"2011-05-16T18:27:42.933\" OwnerDisplayName=\"Aniko\" OwnerUserId=\"279\" ParentId=\"10882\" PostTypeId=\"2\" Score=\"2\" />',\n",
       " '  ',\n",
       " '  <row AnswerCount=\"2\" Body=\"&lt;p&gt;I would like to compute the probability distribution for the length of the fragments which I would obtain by fragmenting a linear rod of length $L$ in the following way:&lt;/p&gt;&#10;&#10;&lt;ol&gt;&#10;&lt;li&gt;I choose at random (uniformly) $n$ breakpoints &lt;/li&gt;&#10;&lt;li&gt;I cut the rod at those breakpoints, creating $(n+1)$ fragments.&lt;/li&gt;&#10;&lt;/ol&gt;&#10;&#10;&lt;p&gt;Now, while it is easy to see that the probability that a stretch of length $x$ does not contain any breakpoint goes like a negative exponential, I don\\'t know how to throw in the information about the length of the rod.&lt;/p&gt;&#10;\" CommentCount=\"7\" CreationDate=\"2011-05-17T16:06:19.143\" Id=\"10897\" LastActivityDate=\"2011-05-18T16:41:17.197\" LastEditDate=\"2011-05-17T16:38:47.773\" LastEditorUserId=\"2970\" OwnerUserId=\"4642\" PostTypeId=\"1\" Score=\"6\" Tags=\"&lt;probability&gt;\" Title=\"Probability distribution of fragment lengths\" ViewCount=\"228\" />',\n",
       " '  ',\n",
       " '  <row Body=\"&lt;p&gt;Let $\\\\{X_i\\\\}$ be the locations of the cuts.&lt;/p&gt;&#10;&#10;&lt;p&gt;I\\'d approach this problem by finding the order statistics $\\\\{Y_i\\\\}$ so that $Y_1$ would be the location of the leftmost cut. Then I\\'d calculate the probability distributions of the differences between the variables $Y_i-Y_{i-1}$. Don\\'t forget to also calculate $Y_1-0$ and $L-Y_n$.&lt;/p&gt;&#10;&#10;&lt;p&gt;Can anyone think of a better way?&lt;/p&gt;&#10;\" CommentCount=\"2\" CreationDate=\"2011-05-17T16:17:19.443\" Id=\"10899\" LastActivityDate=\"2011-05-17T16:17:19.443\" OwnerUserId=\"4637\" ParentId=\"10897\" PostTypeId=\"2\" Score=\"0\" />',\n",
       " '  ']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_lines.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Favorites and scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "I am interested in looking for useful patterns in the data.  If I look at the Post data again (the smaller set, `stats.stackexchange.com`), I see that many things about each post are recorded.  I'm going to start by looking to see if there is a relationship between the number of times a post was favorited (the `FavoriteCount`) and the `Score`.  The score is the number of times the post was upvoted minus the number of times it was downvoted, so it is a measure of how much a post was liked.  I'd expect posts with a higher number of favorites to have better scores, since they're both measurements of how good the post is.\n",
    "\n",
    "Let's aggregate posts by the number of favorites, and find the average score for each number of favorites. Let's do this for the lowest 50 numbers of favorites.\n",
    "\n",
    "**Checkpoints**\n",
    "\n",
    "- Total score across all posts: 299469\n",
    "- Mean of first 50 favorite counts (averaging the keys themselves): 24.76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_parser(s):\n",
    "    try:\n",
    "        tree = etree.fromstring(s.strip())\n",
    "        return dict(tree.attrib)\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_df = post_lines.filter(isRow) \\\n",
    "                .filter(lambda line: not isBadXML(line)) \\\n",
    "                .map(line_parser) \\\n",
    "                .toDF(sampleRatio = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_null_to_zero(s):\n",
    "    if s is None:\n",
    "        return 0\n",
    "    else:\n",
    "        return int(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType, StringType, IntegerType, ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_df = post_df.withColumn('FavoriteCount', \n",
    "                              F.when(F.col('FavoriteCount').isNull(), 0)\\\n",
    "                               .otherwise(F.col('FavoriteCount').cast(IntegerType())))\\\n",
    "                 .withColumn('Score',\n",
    "                            F.when(F.col('Score').isNull(), 0)\\\n",
    "                             .otherwise(F.col('Score').cast(IntegerType()))).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_df = post_df.withColumn('Id', \n",
    "                              F.when(F.col('Id').isNull(), 0)\\\n",
    "                               .otherwise(F.col('Id').cast(IntegerType())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Body: string, CommentCount: string, CreationDate: string, Id: int, LastActivityDate: string, OwnerUserId: string, ParentId: string, PostTypeId: string, Score: int, AnswerCount: string, Tags: string, Title: string, ViewCount: string, AcceptedAnswerId: string, FavoriteCount: int, LastEditDate: string, LastEditorUserId: string]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = post_df.groupby('FavoriteCount')\\\n",
    "             .agg(F.avg('Score').alias('AvgScore'))\\\n",
    "             .sort('FavoriteCount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "xzz = ans.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "favorite_score = [(int(item[0]), item[1]) for item in ans.toPandas().to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2.3398827696988396),\n",
       " (1, 2.7334613999279624),\n",
       " (2, 4.481914893617021),\n",
       " (3, 6.350249584026622),\n",
       " (4, 7.656934306569343)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "favorite_score[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Answer percentage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "I investigate the correlation between a user's reputation and the kind of posts they make. For the 99 users with the highest reputation, single out posts which are either questions or answers and look at the percentage of these posts that are answers: *(answers / (answers + questions))*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "#### Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "* Total questions: 52,060\n",
    "* Total answers: 55,304\n",
    "* Top 99 users' average reputation: 11893.464646464647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Id: string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "User_df = User_lines.filter(isRow) \\\n",
    "                .filter(lambda line: not isBadXML(line)) \\\n",
    "                .map(line_parser) \\\n",
    "                .toDF(sampleRatio = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "User_df = User_df.withColumn('Reputation', \n",
    "                              F.when(F.col('Reputation').isNull(), 0)\\\n",
    "                               .otherwise(F.col('Reputation').cast(IntegerType())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "User_df = User_df.withColumn('Id', \n",
    "                              F.when(F.col('Id').isNull(), 0)\\\n",
    "                               .otherwise(F.col('Id').cast(IntegerType())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[AccountId: string, CreationDate: string, DisplayName: string, DownVotes: string, Id: int, LastAccessDate: string, Reputation: int, UpVotes: string, Views: string]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "User_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_user = User_df.sort('Reputation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcc = ans_user.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc = ans_user.toPandas().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "listov = xc[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50320"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_reputations = [(int(item[4]), item[6]) for item in ans_user.toPandas().to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8373, 3720),\n",
       " (11852, 3732),\n",
       " (1679, 3747),\n",
       " (1108, 3805),\n",
       " (13138, 3821),\n",
       " (17908, 3957),\n",
       " (3601, 3958),\n",
       " (4862, 3971),\n",
       " (22228, 4065),\n",
       " (1005, 4080),\n",
       " (35989, 4092),\n",
       " (2074, 4127),\n",
       " (52554, 4147),\n",
       " (11887, 4149),\n",
       " (223, 4192),\n",
       " (2860, 4204),\n",
       " (1307, 4238),\n",
       " (8413, 4438),\n",
       " (5862, 4656),\n",
       " (8076, 4795),\n",
       " (307, 4934),\n",
       " (14188, 5042),\n",
       " (264, 5085),\n",
       " (8507, 5315),\n",
       " (13047, 5398),\n",
       " (334, 5444),\n",
       " (22311, 5500),\n",
       " (25, 5661),\n",
       " (364, 5739),\n",
       " (253, 5762),\n",
       " (25433, 5775),\n",
       " (795, 5849),\n",
       " (1934, 5967),\n",
       " (11981, 5970),\n",
       " (6029, 6040),\n",
       " (44269, 6127),\n",
       " (2126, 6145),\n",
       " (36041, 6149),\n",
       " (8402, 6208),\n",
       " (2669, 6352),\n",
       " (279, 6367),\n",
       " (442, 6588),\n",
       " (196, 6682),\n",
       " (4257, 6694),\n",
       " (21054, 6716),\n",
       " (1909, 6814),\n",
       " (7250, 6888),\n",
       " (8, 6948),\n",
       " (5, 6962),\n",
       " (401, 7116),\n",
       " (1352, 7552),\n",
       " (26338, 7608),\n",
       " (10849, 7725),\n",
       " (32036, 7729),\n",
       " (23853, 7765),\n",
       " (1764, 7971),\n",
       " (28666, 8013),\n",
       " (251, 8221),\n",
       " (4376, 8629),\n",
       " (3019, 8794),\n",
       " (8013, 9047),\n",
       " (3382, 9294),\n",
       " (1036, 9530),\n",
       " (1739, 9619),\n",
       " (7071, 10045),\n",
       " (4598, 10383),\n",
       " (7224, 10394),\n",
       " (2817, 10552),\n",
       " (7828, 10728),\n",
       " (9394, 10750),\n",
       " (2958, 11083),\n",
       " (6633, 11662),\n",
       " (7972, 11795),\n",
       " (603, 11830),\n",
       " (7555, 11865),\n",
       " (5836, 11989),\n",
       " (1390, 12098),\n",
       " (2392, 12491),\n",
       " (449, 13078),\n",
       " (17230, 13557),\n",
       " (601, 14100),\n",
       " (2970, 14500),\n",
       " (88, 14768),\n",
       " (3277, 16131),\n",
       " (5739, 16854),\n",
       " (22047, 17719),\n",
       " (4856, 18866),\n",
       " (2116, 19312),\n",
       " (159, 20133),\n",
       " (887, 20315),\n",
       " (28746, 22706),\n",
       " (11032, 23102),\n",
       " (183, 23610),\n",
       " (4253, 25406),\n",
       " (4505, 27599),\n",
       " (930, 32283),\n",
       " (7290, 46907),\n",
       " (686, 47334),\n",
       " (805, 92624),\n",
       " (919, 100976)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_reputations[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AboutMe',\n",
       " 'AccountId',\n",
       " 'Age',\n",
       " 'CreationDate',\n",
       " 'DisplayName',\n",
       " 'DownVotes',\n",
       " 'Id',\n",
       " 'LastAccessDate',\n",
       " 'Location',\n",
       " 'Reputation',\n",
       " 'UpVotes',\n",
       " 'Views',\n",
       " 'WebsiteUrl',\n",
       " 'ProfileImageUrl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "User_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Body',\n",
       " 'CommentCount',\n",
       " 'CreationDate',\n",
       " 'Id',\n",
       " 'LastActivityDate',\n",
       " 'OwnerUserId',\n",
       " 'ParentId',\n",
       " 'PostTypeId',\n",
       " 'Score',\n",
       " 'AcceptedAnswerId',\n",
       " 'AnswerCount',\n",
       " 'FavoriteCount',\n",
       " 'LastEditDate',\n",
       " 'LastEditorUserId',\n",
       " 'Tags',\n",
       " 'Title',\n",
       " 'ViewCount',\n",
       " 'CommunityOwnedDate']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_post = post_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         10893\n",
       "1         10894\n",
       "2         10897\n",
       "3         10899\n",
       "4         10900\n",
       "          ...  \n",
       "108736    73928\n",
       "108737    73929\n",
       "108738    73930\n",
       "108739    73931\n",
       "108740    73932\n",
       "Name: Id, Length: 108741, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_post['Id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108741"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pandas_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Id</th>\n",
       "      <th>LastActivityDate</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>ParentId</th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>Score</th>\n",
       "      <th>AcceptedAnswerId</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>FavoriteCount</th>\n",
       "      <th>LastEditDate</th>\n",
       "      <th>LastEditorUserId</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Title</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>CommunityOwnedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26072</th>\n",
       "      <td>&lt;p&gt;A white noise process is one with a mean ze...</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-02-10T22:23:25.730</td>\n",
       "      <td>7071</td>\n",
       "      <td>2011-02-10T22:23:25.730</td>\n",
       "      <td>449</td>\n",
       "      <td>7070</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Body CommentCount  \\\n",
       "26072  <p>A white noise process is one with a mean ze...            5   \n",
       "\n",
       "                  CreationDate    Id         LastActivityDate OwnerUserId  \\\n",
       "26072  2011-02-10T22:23:25.730  7071  2011-02-10T22:23:25.730         449   \n",
       "\n",
       "      ParentId PostTypeId  Score AcceptedAnswerId AnswerCount  FavoriteCount  \\\n",
       "26072     7070          2     10             None        None              0   \n",
       "\n",
       "      LastEditDate LastEditorUserId  Tags Title ViewCount CommunityOwnedDate  \n",
       "26072         None             None  None  None      None               None  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_post[pandas_post['Id'] == 7071]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_user = User_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    108741.000000\n",
       "mean      68685.006796\n",
       "std       41416.350973\n",
       "min           1.000000\n",
       "25%       31215.000000\n",
       "50%       67914.000000\n",
       "75%      104838.000000\n",
       "max      140829.000000\n",
       "Name: Id, dtype: float64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_post['Id'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    50320.000000\n",
       "mean     35805.445767\n",
       "std      20938.418199\n",
       "min         -1.000000\n",
       "25%      17110.750000\n",
       "50%      36342.500000\n",
       "75%      54826.250000\n",
       "max      70649.000000\n",
       "Name: Id, dtype: float64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_user['Id'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AccountId', 'CreationDate', 'DisplayName', 'DownVotes', 'Id',\n",
       "       'LastAccessDate', 'Reputation', 'UpVotes', 'Views', 'ProfileImageUrl'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_user.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccountId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>DownVotes</th>\n",
       "      <th>Id</th>\n",
       "      <th>LastAccessDate</th>\n",
       "      <th>Reputation</th>\n",
       "      <th>UpVotes</th>\n",
       "      <th>Views</th>\n",
       "      <th>ProfileImageUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5872878</td>\n",
       "      <td>2015-03-02T18:42:20.510</td>\n",
       "      <td>Lars Reeker</td>\n",
       "      <td>0</td>\n",
       "      <td>70185</td>\n",
       "      <td>2015-03-02T18:42:20.510</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://lh3.googleusercontent.com/-Y7GNsydm-mc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5872995</td>\n",
       "      <td>2015-03-02T19:04:13.380</td>\n",
       "      <td>Vra</td>\n",
       "      <td>0</td>\n",
       "      <td>70186</td>\n",
       "      <td>2015-03-06T15:45:57.590</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5873177</td>\n",
       "      <td>2015-03-02T19:40:16.420</td>\n",
       "      <td>Aroona</td>\n",
       "      <td>0</td>\n",
       "      <td>70187</td>\n",
       "      <td>2015-03-02T19:40:16.420</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.gravatar.com/avatar/e0e90702da3203...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5873184</td>\n",
       "      <td>2015-03-02T19:46:45.400</td>\n",
       "      <td>Yazeed</td>\n",
       "      <td>0</td>\n",
       "      <td>70188</td>\n",
       "      <td>2015-03-02T19:46:45.400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.gravatar.com/avatar/f5e666cb769dfb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228681</td>\n",
       "      <td>2015-03-02T19:56:37.233</td>\n",
       "      <td>Taimur</td>\n",
       "      <td>0</td>\n",
       "      <td>70189</td>\n",
       "      <td>2015-03-03T09:26:04.020</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://i.stack.imgur.com/PhYFp.jpg?s=128&amp;g=1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AccountId             CreationDate  DisplayName DownVotes     Id  \\\n",
       "0   5872878  2015-03-02T18:42:20.510  Lars Reeker         0  70185   \n",
       "1   5872995  2015-03-02T19:04:13.380          Vra         0  70186   \n",
       "2   5873177  2015-03-02T19:40:16.420       Aroona         0  70187   \n",
       "3   5873184  2015-03-02T19:46:45.400       Yazeed         0  70188   \n",
       "4    228681  2015-03-02T19:56:37.233       Taimur         0  70189   \n",
       "\n",
       "            LastAccessDate  Reputation UpVotes Views  \\\n",
       "0  2015-03-02T18:42:20.510           1       0     0   \n",
       "1  2015-03-06T15:45:57.590           6       0     1   \n",
       "2  2015-03-02T19:40:16.420           1       0     0   \n",
       "3  2015-03-02T19:46:45.400           1       0     0   \n",
       "4  2015-03-03T09:26:04.020         101       0     0   \n",
       "\n",
       "                                     ProfileImageUrl  \n",
       "0  https://lh3.googleusercontent.com/-Y7GNsydm-mc...  \n",
       "1                                               None  \n",
       "2  https://www.gravatar.com/avatar/e0e90702da3203...  \n",
       "3  https://www.gravatar.com/avatar/f5e666cb769dfb...  \n",
       "4       http://i.stack.imgur.com/PhYFp.jpg?s=128&g=1  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = pandas_post.merge(pandas_user, how='left', on = 'Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108741"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>PostTypeId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;I am trained in frequentist statistics (eco...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;p&gt;I have been a member of CrossValidated for ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;p&gt;If I understand the question, couldn't you ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;p&gt;I have $Y$ measurements per several Subject...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;p&gt;$y_i=\\beta_0+\\beta_1x_i+\\varepsilon $ is a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39866</th>\n",
       "      <td>&lt;p&gt;I'm having trouble to fit and simulate a &lt;c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39867</th>\n",
       "      <td>&lt;p&gt;This may well be a textbook question - I am...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39868</th>\n",
       "      <td>&lt;p&gt;I have a time series count data by customer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39869</th>\n",
       "      <td>&lt;p&gt;I am attempting to monitor the performance ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39870</th>\n",
       "      <td>&lt;p&gt;Because brightness is a response with indep...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39871 rows Ã 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Body PostTypeId\n",
       "0      <p>I am trained in frequentist statistics (eco...          2\n",
       "1      <p>I have been a member of CrossValidated for ...          6\n",
       "2      <p>If I understand the question, couldn't you ...          2\n",
       "3      <p>I have $Y$ measurements per several Subject...          1\n",
       "4      <p>$y_i=\\beta_0+\\beta_1x_i+\\varepsilon $ is a ...          1\n",
       "...                                                  ...        ...\n",
       "39866  <p>I'm having trouble to fit and simulate a <c...          1\n",
       "39867  <p>This may well be a textbook question - I am...          1\n",
       "39868  <p>I have a time series count data by customer...          1\n",
       "39869  <p>I am attempting to monitor the performance ...          1\n",
       "39870  <p>Because brightness is a response with indep...          2\n",
       "\n",
       "[39871 rows x 2 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colom = ['Body','PostTypeId']\n",
    "df[colom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = dfx.sort_values(by='Reputation', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dfff['PostTypeId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Id', 'Reputation', 'PostTypeId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfff = dff[cols] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffff = dfff.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Reputation</th>\n",
       "      <th>PostTypeId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20564</th>\n",
       "      <td>919</td>\n",
       "      <td>100976.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20459</th>\n",
       "      <td>805</td>\n",
       "      <td>92624.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20348</th>\n",
       "      <td>686</td>\n",
       "      <td>47334.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26270</th>\n",
       "      <td>7290</td>\n",
       "      <td>46907.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20573</th>\n",
       "      <td>930</td>\n",
       "      <td>32283.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108736</th>\n",
       "      <td>73928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108737</th>\n",
       "      <td>73929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108738</th>\n",
       "      <td>73930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108739</th>\n",
       "      <td>73931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108740</th>\n",
       "      <td>73932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108741 rows Ã 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id  Reputation PostTypeId\n",
       "20564     919    100976.0          2\n",
       "20459     805     92624.0          1\n",
       "20348     686     47334.0          2\n",
       "26270    7290     46907.0          2\n",
       "20573     930     32283.0          2\n",
       "...       ...         ...        ...\n",
       "108736  73928         0.0          2\n",
       "108737  73929         0.0          1\n",
       "108738  73930         0.0          1\n",
       "108739  73931         0.0          1\n",
       "108740  73932         0.0          2\n",
       "\n",
       "[108741 rows x 3 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dffff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffff['questions'] = [1 if x == '1' else 0 for x in dffff['PostTypeId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Reputation</th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20564</th>\n",
       "      <td>919</td>\n",
       "      <td>100976.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20459</th>\n",
       "      <td>805</td>\n",
       "      <td>92624.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20348</th>\n",
       "      <td>686</td>\n",
       "      <td>47334.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26270</th>\n",
       "      <td>7290</td>\n",
       "      <td>46907.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20573</th>\n",
       "      <td>930</td>\n",
       "      <td>32283.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108736</th>\n",
       "      <td>73928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108737</th>\n",
       "      <td>73929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108738</th>\n",
       "      <td>73930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108739</th>\n",
       "      <td>73931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108740</th>\n",
       "      <td>73932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108741 rows Ã 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id  Reputation PostTypeId  questions\n",
       "20564     919    100976.0          2          0\n",
       "20459     805     92624.0          1          1\n",
       "20348     686     47334.0          2          0\n",
       "26270    7290     46907.0          2          0\n",
       "20573     930     32283.0          2          0\n",
       "...       ...         ...        ...        ...\n",
       "108736  73928         0.0          2          0\n",
       "108737  73929         0.0          1          1\n",
       "108738  73930         0.0          1          1\n",
       "108739  73931         0.0          1          1\n",
       "108740  73932         0.0          2          0\n",
       "\n",
       "[108741 rows x 4 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dffff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffff['answers'] = [1 if x == '2' else 0 for x in dffff['PostTypeId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Reputation</th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20564</th>\n",
       "      <td>919</td>\n",
       "      <td>100976.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20459</th>\n",
       "      <td>805</td>\n",
       "      <td>92624.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20348</th>\n",
       "      <td>686</td>\n",
       "      <td>47334.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26270</th>\n",
       "      <td>7290</td>\n",
       "      <td>46907.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20573</th>\n",
       "      <td>930</td>\n",
       "      <td>32283.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108736</th>\n",
       "      <td>73928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108737</th>\n",
       "      <td>73929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108738</th>\n",
       "      <td>73930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108739</th>\n",
       "      <td>73931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108740</th>\n",
       "      <td>73932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108741 rows Ã 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id  Reputation PostTypeId  questions  answers\n",
       "20564     919    100976.0          2          0        1\n",
       "20459     805     92624.0          1          1        0\n",
       "20348     686     47334.0          2          0        1\n",
       "26270    7290     46907.0          2          0        1\n",
       "20573     930     32283.0          2          0        1\n",
       "...       ...         ...        ...        ...      ...\n",
       "108736  73928         0.0          2          0        1\n",
       "108737  73929         0.0          1          1        0\n",
       "108738  73930         0.0          1          1        0\n",
       "108739  73931         0.0          1          1        0\n",
       "108740  73932         0.0          2          0        1\n",
       "\n",
       "[108741 rows x 5 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dffff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Reputation</th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26072</th>\n",
       "      <td>7071</td>\n",
       "      <td>10045.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  Reputation PostTypeId  questions  answers\n",
       "26072  7071     10045.0          2          0        1"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dffff[dffff['Id'] == 7071]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-149-1e35b6f799a2>:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  x = dffff.groupby(by=['Id', 'Reputation'])['questions', 'answers'].apply(lambda x : x.astype(int).sum())\n"
     ]
    }
   ],
   "source": [
    "x = dffff.groupby(by=['Id', 'Reputation'])['questions', 'answers'].apply(lambda x : x.astype(int).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th>Reputation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>101.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>101.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>101.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>6962.0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               questions  answers\n",
       "Id Reputation                    \n",
       "1  0.0                 1        0\n",
       "2  101.0               1        0\n",
       "3  101.0               1        0\n",
       "4  101.0               1        0\n",
       "5  6962.0              0        1"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>108741.000000</td>\n",
       "      <td>108741.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.478752</td>\n",
       "      <td>0.508585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499551</td>\n",
       "      <td>0.499929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           questions        answers\n",
       "count  108741.000000  108741.000000\n",
       "mean        0.478752       0.508585\n",
       "std         0.499551       0.499929\n",
       "min         0.000000       0.000000\n",
       "25%         0.000000       0.000000\n",
       "50%         0.000000       1.000000\n",
       "75%         1.000000       1.000000\n",
       "max         1.000000       1.000000"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_lines = sc.textFile('spark-stats-data/allUsers/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = user_lines.filter(isRow) \\\n",
    "                    .filter(lambda line : not isBadXML(line)) \\\n",
    "                    .map(line_parser)\\\n",
    "                    .toDF(sampleRatio=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[AccountId: string, CreationDate: string, DisplayName: string, DownVotes: string, Id: string, LastAccessDate: string, ProfileImageUrl: string, Reputation: string, UpVotes: string, Views: string, AboutMe: string, Age: string, Location: string, WebsiteUrl: string]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnd_count = lambda cond : F.sum(F.when(cond, 1).otherwise(0))\n",
    "\n",
    "joined = user_df.withColumn(\"Reputation\", user_df.Reputation.cast('int'))\\\n",
    "                .join(post_df,\n",
    "                      user_df.Id == post_df.OwnerUserId)\\\n",
    "                .groupBy(post_df.OwnerUserId)\\\n",
    "                .agg((cnd_count(post_df[\"PostTypeId\"] == '2')/\n",
    "                     (cnd_count(post_df[\"PostTypeId\"] == '2')+\n",
    "                       cnd_count(post_df[\"PostTypeId\"] == '1'))).alias(\"ans_ratio\"),\n",
    "                     F.min(\"Reputation\").alias(\"Reputation\"))\\\n",
    "                .sort('Reputation', ascending=False)\\\n",
    "                .withColumn('OwnerUserId', F.col('OwnerUserId').cast('int'))\\\n",
    "                .limit(99).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_percentage = list(zip(list(joined['OwnerUserId'])[:99],list(joined['ans_ratio'])[:99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_percentage.append((-1, joined['ans_ratio'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## First question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "I'd expect the first **question** a user asks to be indicative of their future behavior.  I'll dig more into that in the next problem, but for now let's see the relationship between reputation and how long it took each person to ask their first question.\n",
    "\n",
    "For each user that asked a question, let's find the difference between when their account was created (`CreationDate` for the User) and when they asked their first question (`CreationDate` for their first question). Let's return this time difference in days (round down, so 2.7 days counts as 2 days) for the 100 users with the highest reputation, in the form\n",
    "\n",
    "`(UserId, Days)`\n",
    "\n",
    "**Checkpoints**\n",
    "- Users that asked a question: 23134\n",
    "- Average number of days (round each user's days, then average): 30.1074258"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = dfx['CreationDate_y'][0].split(\"T\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2012, 4, 26)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.strptime(tr,'%Y-%m-%d').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx['CreationsDate'] = [datetime.strptime(x.split('T')[0], '%Y-%m-%d').date() for x in dfx['CreationDate_x']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>CreationDate_x</th>\n",
       "      <th>Id</th>\n",
       "      <th>LastActivityDate</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>ParentId</th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>Score</th>\n",
       "      <th>AcceptedAnswerId</th>\n",
       "      <th>...</th>\n",
       "      <th>AccountId</th>\n",
       "      <th>CreationDate_y</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>DownVotes</th>\n",
       "      <th>LastAccessDate</th>\n",
       "      <th>Reputation</th>\n",
       "      <th>UpVotes</th>\n",
       "      <th>Views</th>\n",
       "      <th>ProfileImageUrl</th>\n",
       "      <th>CreationsDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;I'm developing an application in which user...</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-05-16T17:39:58.170</td>\n",
       "      <td>10893</td>\n",
       "      <td>2011-06-02T22:10:16.550</td>\n",
       "      <td>4638</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>87574</td>\n",
       "      <td>2012-04-26T09:47:40.967</td>\n",
       "      <td>Ben J</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-04-14T09:20:59.630</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>2011-05-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;p&gt;Perhaps you could extend the idea of using ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-05-16T18:27:42.933</td>\n",
       "      <td>10894</td>\n",
       "      <td>2011-05-16T18:27:42.933</td>\n",
       "      <td>279</td>\n",
       "      <td>10882</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>416858</td>\n",
       "      <td>2012-04-26T10:38:14.877</td>\n",
       "      <td>Peter Lewis</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-07-12T18:33:32.253</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>2011-05-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;p&gt;I would like to compute the probability dis...</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-05-17T16:06:19.143</td>\n",
       "      <td>10897</td>\n",
       "      <td>2011-05-18T16:41:17.197</td>\n",
       "      <td>4642</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>44643</td>\n",
       "      <td>2012-04-26T14:02:18.303</td>\n",
       "      <td>Goz</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-06-14T10:32:37.827</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2011-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;p&gt;Let $\\{X_i\\}$ be the locations of the cuts....</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-05-17T16:17:19.443</td>\n",
       "      <td>10899</td>\n",
       "      <td>2011-05-17T16:17:19.443</td>\n",
       "      <td>4637</td>\n",
       "      <td>10897</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1438027</td>\n",
       "      <td>2012-04-26T14:47:29.747</td>\n",
       "      <td>user10899</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-07-20T02:47:58.513</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>2011-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;p&gt;I have to generate random numbers for my al...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-05-17T17:13:30.487</td>\n",
       "      <td>10900</td>\n",
       "      <td>2012-07-13T07:12:05.503</td>\n",
       "      <td>4319</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1438525</td>\n",
       "      <td>2012-04-26T17:41:34.567</td>\n",
       "      <td>user1359363</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-04-23T18:47:05.450</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>2011-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108736</th>\n",
       "      <td>&lt;p&gt;This is an expected result. The matrix $\\Pi...</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-10-28T08:29:21.737</td>\n",
       "      <td>73928</td>\n",
       "      <td>2013-10-28T08:29:21.737</td>\n",
       "      <td>2116</td>\n",
       "      <td>46688</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108737</th>\n",
       "      <td>&lt;p&gt;I have a set of independent data and depend...</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-10-28T08:36:36.887</td>\n",
       "      <td>73929</td>\n",
       "      <td>2013-10-28T08:40:26.223</td>\n",
       "      <td>31986</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108738</th>\n",
       "      <td>&lt;p&gt;The stochastic process $(X_t)_{t\\in T}$ is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-10-28T09:44:43.930</td>\n",
       "      <td>73930</td>\n",
       "      <td>2013-10-28T10:06:38.203</td>\n",
       "      <td>30496</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108739</th>\n",
       "      <td>&lt;p&gt;I have a very particular question, I have s...</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-10-28T10:00:02.867</td>\n",
       "      <td>73931</td>\n",
       "      <td>2015-03-02T06:33:34.697</td>\n",
       "      <td>28322</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108740</th>\n",
       "      <td>&lt;p&gt;If the form of the kernel is known &lt;em&gt;(man...</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-10-28T10:06:38.203</td>\n",
       "      <td>73932</td>\n",
       "      <td>2013-10-28T10:06:38.203</td>\n",
       "      <td>16137</td>\n",
       "      <td>73930</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-10-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108741 rows Ã 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Body CommentCount  \\\n",
       "0       <p>I'm developing an application in which user...            0   \n",
       "1       <p>Perhaps you could extend the idea of using ...            5   \n",
       "2       <p>I would like to compute the probability dis...            7   \n",
       "3       <p>Let $\\{X_i\\}$ be the locations of the cuts....            2   \n",
       "4       <p>I have to generate random numbers for my al...            1   \n",
       "...                                                   ...          ...   \n",
       "108736  <p>This is an expected result. The matrix $\\Pi...            0   \n",
       "108737  <p>I have a set of independent data and depend...            5   \n",
       "108738  <p>The stochastic process $(X_t)_{t\\in T}$ is ...            0   \n",
       "108739  <p>I have a very particular question, I have s...            1   \n",
       "108740  <p>If the form of the kernel is known <em>(man...            0   \n",
       "\n",
       "                 CreationDate_x     Id         LastActivityDate OwnerUserId  \\\n",
       "0       2011-05-16T17:39:58.170  10893  2011-06-02T22:10:16.550        4638   \n",
       "1       2011-05-16T18:27:42.933  10894  2011-05-16T18:27:42.933         279   \n",
       "2       2011-05-17T16:06:19.143  10897  2011-05-18T16:41:17.197        4642   \n",
       "3       2011-05-17T16:17:19.443  10899  2011-05-17T16:17:19.443        4637   \n",
       "4       2011-05-17T17:13:30.487  10900  2012-07-13T07:12:05.503        4319   \n",
       "...                         ...    ...                      ...         ...   \n",
       "108736  2013-10-28T08:29:21.737  73928  2013-10-28T08:29:21.737        2116   \n",
       "108737  2013-10-28T08:36:36.887  73929  2013-10-28T08:40:26.223       31986   \n",
       "108738  2013-10-28T09:44:43.930  73930  2013-10-28T10:06:38.203       30496   \n",
       "108739  2013-10-28T10:00:02.867  73931  2015-03-02T06:33:34.697       28322   \n",
       "108740  2013-10-28T10:06:38.203  73932  2013-10-28T10:06:38.203       16137   \n",
       "\n",
       "       ParentId PostTypeId  Score AcceptedAnswerId  ... AccountId  \\\n",
       "0          None          1      2             None  ...     87574   \n",
       "1         10882          2      2             None  ...    416858   \n",
       "2          None          1      6             None  ...     44643   \n",
       "3         10897          2      0             None  ...   1438027   \n",
       "4          None          1      3             None  ...   1438525   \n",
       "...         ...        ...    ...              ...  ...       ...   \n",
       "108736    46688          2      0             None  ...       NaN   \n",
       "108737     None          1      2             None  ...       NaN   \n",
       "108738     None          1      2             None  ...       NaN   \n",
       "108739     None          1      2             None  ...       NaN   \n",
       "108740    73930          2      2             None  ...       NaN   \n",
       "\n",
       "                 CreationDate_y  DisplayName DownVotes  \\\n",
       "0       2012-04-26T09:47:40.967        Ben J         0   \n",
       "1       2012-04-26T10:38:14.877  Peter Lewis         0   \n",
       "2       2012-04-26T14:02:18.303          Goz         0   \n",
       "3       2012-04-26T14:47:29.747    user10899         0   \n",
       "4       2012-04-26T17:41:34.567  user1359363         0   \n",
       "...                         ...          ...       ...   \n",
       "108736                      NaN          NaN       NaN   \n",
       "108737                      NaN          NaN       NaN   \n",
       "108738                      NaN          NaN       NaN   \n",
       "108739                      NaN          NaN       NaN   \n",
       "108740                      NaN          NaN       NaN   \n",
       "\n",
       "                 LastAccessDate Reputation UpVotes Views ProfileImageUrl  \\\n",
       "0       2014-04-14T09:20:59.630      106.0       0     7            None   \n",
       "1       2012-07-12T18:33:32.253        1.0       0     0            None   \n",
       "2       2013-06-14T10:32:37.827      108.0       1     1            None   \n",
       "3       2012-07-20T02:47:58.513       11.0       0     3            None   \n",
       "4       2014-04-23T18:47:05.450       11.0       0     3            None   \n",
       "...                         ...        ...     ...   ...             ...   \n",
       "108736                      NaN        NaN     NaN   NaN             NaN   \n",
       "108737                      NaN        NaN     NaN   NaN             NaN   \n",
       "108738                      NaN        NaN     NaN   NaN             NaN   \n",
       "108739                      NaN        NaN     NaN   NaN             NaN   \n",
       "108740                      NaN        NaN     NaN   NaN             NaN   \n",
       "\n",
       "       CreationsDate  \n",
       "0         2011-05-16  \n",
       "1         2011-05-16  \n",
       "2         2011-05-17  \n",
       "3         2011-05-17  \n",
       "4         2011-05-17  \n",
       "...              ...  \n",
       "108736    2013-10-28  \n",
       "108737    2013-10-28  \n",
       "108738    2013-10-28  \n",
       "108739    2013-10-28  \n",
       "108740    2013-10-28  \n",
       "\n",
       "[108741 rows x 28 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = user_df.withColumn('UserCreationDate', F.to_timestamp('CreationDate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+\n",
      "|sum(CASE WHEN (PostTypeId = 1) THEN 1 ELSE 0 END)|\n",
      "+-------------------------------------------------+\n",
      "|                                            52060|\n",
      "+-------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "post_df.agg((cnd_count(post_df.PostTypeId == '1'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_df_firstq = post_df.withColumn('PostCreationDate', F.to_timestamp('CreationDate'))\\\n",
    "                        .groupBy('OwnerUserId', 'PostTypeId')\\\n",
    "                        .agg((F.min('PostCreationDate')).alias('FirstPostDate')).alias('grouped')\\\n",
    "                        .filter(F.col('grouped.PostTypeId')=='1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined2= post_df_firstq.join(user_df,\n",
    "                             user_df.Id == post_df_firstq.OwnerUserId)\n",
    "\n",
    "ans2 = joined2.withColumn('DiffinSec', F.col('FirstPostDate').cast('long') - F.col('UserCreationDate').cast('long'))\\\n",
    "               .withColumn('DiffinDay', F.floor(F.col('DiffinSec')/3600/24))\\\n",
    "               .withColumn(\"Reputation\", user_df.Reputation.cast('int'))\\\n",
    "               .sort('Reputation', ascending=False)\\\n",
    "               .withColumn('OwnerUserId', F.col('OwnerUserId').cast('int'))\\\n",
    "               .limit(100).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FirstPostDate</th>\n",
       "      <th>UserCreationDate</th>\n",
       "      <th>DiffinDay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-08-17 13:10:29.173</td>\n",
       "      <td>2010-08-13 15:29:47.140</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-06-07 00:14:12.397</td>\n",
       "      <td>2010-08-07 08:40:07.287</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-02-10 15:35:57.853</td>\n",
       "      <td>2010-08-03 19:42:40.907</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-11-09 05:51:55.263</td>\n",
       "      <td>2011-11-09 04:43:15.613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-08-18 20:36:59.617</td>\n",
       "      <td>2010-08-13 20:50:47.397</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2011-02-18 02:40:12.390</td>\n",
       "      <td>2010-07-19 19:09:39.723</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2013-10-15 08:21:54.933</td>\n",
       "      <td>2011-08-14 21:52:19.277</td>\n",
       "      <td>792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2010-09-10 12:51:35.787</td>\n",
       "      <td>2010-08-31 10:07:27.890</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2010-07-31 09:39:47.323</td>\n",
       "      <td>2010-07-26 20:58:01.777</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2010-12-09 14:49:52.150</td>\n",
       "      <td>2010-12-09 01:48:37.523</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FirstPostDate        UserCreationDate  DiffinDay\n",
       "0  2010-08-17 13:10:29.173 2010-08-13 15:29:47.140          3\n",
       "1  2012-06-07 00:14:12.397 2010-08-07 08:40:07.287        669\n",
       "2  2011-02-10 15:35:57.853 2010-08-03 19:42:40.907        190\n",
       "3  2011-11-09 05:51:55.263 2011-11-09 04:43:15.613          0\n",
       "4  2010-08-18 20:36:59.617 2010-08-13 20:50:47.397          4\n",
       "..                     ...                     ...        ...\n",
       "95 2011-02-18 02:40:12.390 2010-07-19 19:09:39.723        213\n",
       "96 2013-10-15 08:21:54.933 2011-08-14 21:52:19.277        792\n",
       "97 2010-09-10 12:51:35.787 2010-08-31 10:07:27.890         10\n",
       "98 2010-07-31 09:39:47.323 2010-07-26 20:58:01.777          4\n",
       "99 2010-12-09 14:49:52.150 2010-12-09 01:48:37.523          0\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans2[['FirstPostDate','UserCreationDate','DiffinDay']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_question = list(zip(list(ans2['OwnerUserId'])[:100],list(ans2['DiffinDay'])[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(919, 3),\n",
       " (805, 669),\n",
       " (686, 190),\n",
       " (7290, 0),\n",
       " (930, 4),\n",
       " (4253, 351),\n",
       " (183, 0),\n",
       " (11032, 1),\n",
       " (28746, 19),\n",
       " (887, 22),\n",
       " (159, 0),\n",
       " (2116, 187),\n",
       " (4856, 42),\n",
       " (5739, 147),\n",
       " (3277, 0),\n",
       " (88, 0),\n",
       " (601, 19),\n",
       " (17230, 173),\n",
       " (2392, 42),\n",
       " (1390, 117),\n",
       " (5836, 0),\n",
       " (603, 41),\n",
       " (7972, 30),\n",
       " (6633, 46),\n",
       " (2958, 63),\n",
       " (9394, 205),\n",
       " (7828, 64),\n",
       " (2817, 0),\n",
       " (7224, 145),\n",
       " (4598, 236),\n",
       " (7071, 0),\n",
       " (1739, 1517),\n",
       " (1036, 5),\n",
       " (8013, 6),\n",
       " (3019, 0),\n",
       " (4376, 58),\n",
       " (251, 2),\n",
       " (28666, 0),\n",
       " (1764, 1),\n",
       " (32036, 86),\n",
       " (10849, 23),\n",
       " (26338, 0),\n",
       " (1352, 0),\n",
       " (401, 34),\n",
       " (5, 0),\n",
       " (8, 0),\n",
       " (7250, 156),\n",
       " (1909, 87),\n",
       " (21054, 53),\n",
       " (4257, 27),\n",
       " (196, 0),\n",
       " (442, 28),\n",
       " (2669, 20),\n",
       " (8402, 0),\n",
       " (36041, 121),\n",
       " (44269, 0),\n",
       " (11981, 0),\n",
       " (1934, 0),\n",
       " (795, 0),\n",
       " (25433, 70),\n",
       " (253, 12),\n",
       " (364, 7),\n",
       " (25, 0),\n",
       " (22311, 0),\n",
       " (13047, 84),\n",
       " (8507, 82),\n",
       " (264, 70),\n",
       " (14188, 0),\n",
       " (8076, 28),\n",
       " (8413, 1153),\n",
       " (1307, 3),\n",
       " (2860, 0),\n",
       " (223, 1),\n",
       " (11887, 114),\n",
       " (52554, 0),\n",
       " (35989, 319),\n",
       " (1005, 42),\n",
       " (22228, 28),\n",
       " (4862, 7),\n",
       " (3601, 1343),\n",
       " (13138, 0),\n",
       " (1108, 65),\n",
       " (1679, 2),\n",
       " (8373, 419),\n",
       " (1191, 326),\n",
       " (2129, 332),\n",
       " (2645, 0),\n",
       " (1381, 0),\n",
       " (8141, 0),\n",
       " (858, 523),\n",
       " (11867, 2),\n",
       " (1569, 0),\n",
       " (8451, 549),\n",
       " (7365, 10),\n",
       " (25212, 367),\n",
       " (26, 213),\n",
       " (5829, 792),\n",
       " (1124, 10),\n",
       " (339, 4),\n",
       " (2310, 0)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Identify veterans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "It can be interesting to think about what factors influence a user to remain active on the site over a long period of time. In order not to bias the results towards older users, I'll define a time window between 100 and 150 days after account creation. If the user has made a post in this time, I'll consider them active and well on their way to being veterans of the site; if not, they are inactive and were likely brief users.\n",
    "\n",
    "Let's see if there are differences between the first ever question posts of \"veterans\" vs. \"brief users\". For each group separately, average the score, views, number of answers, and number of favorites of the users' **first question**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "#### Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "* Total brief users: 24,864\n",
    "* Total veteran users: 2,027"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_df = post_df.withColumn('PostCreationDate', F.to_timestamp('CreationDate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined3 = post_df.join(user_df,\n",
    "                    user_df.Id == post_df.OwnerUserId)\\\n",
    "                .withColumn('DiffinSec', F.col('PostCreationDate').cast('long') - \n",
    "                                        F.col('UserCreationDate').cast('long'))\\\n",
    "                .withColumn('DiffinDay', F.floor(F.col('DiffinSec')/3600/24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans3 = joined3.withColumn('Veteran',\n",
    "            F.when((joined3.DiffinDay < 150) & (joined3.DiffinDay >=100), 1).otherwise(0))\n",
    "#                 .select(['PostCreationDate', 'UserCreationDate', 'DiffinDay','Veteran']).show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans4 = ans3.groupby('OwnerUserId')\\\n",
    "            .agg(F.max('Veteran').alias('Veteran'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans5 = post_df_firstq.join(post_df.drop('OwnerUserId'),\n",
    "                           post_df_firstq.FirstPostDate == post_df.PostCreationDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+------------------+------------------+\n",
      "|       avg_score|         avg_view|           avg_ans|           avg_fav|\n",
      "+----------------+-----------------+------------------+------------------+\n",
      "|3.54370533260033|926.3982398239824|1.2981298129812981|1.3001649257833974|\n",
      "+----------------+-----------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ans5.join(ans4,\n",
    "         ans5.OwnerUserId == ans4.OwnerUserId)\\\n",
    "    .filter(F.col('Veteran')==1)\\\n",
    "    .withColumn('AnswerCount',F.col('AnswerCount').cast('int'))\\\n",
    "    .withColumn('ViewCount',F.col('ViewCount').cast('int'))\\\n",
    "    .agg(F.avg(\"Score\").alias(\"avg_score\"), \\\n",
    "         F.avg(\"ViewCount\").alias(\"avg_view\"), \\\n",
    "         F.avg(\"AnswerCount\").alias(\"avg_ans\"), \\\n",
    "         F.avg(\"FavoriteCount\").alias(\"avg_fav\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+------------------+------------------+\n",
      "|        avg_score|         avg_view|           avg_ans|           avg_fav|\n",
      "+-----------------+-----------------+------------------+------------------+\n",
      "|2.100892857142857|553.4952533132813|0.9706739355202557|0.5757988721804511|\n",
      "+-----------------+-----------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ans5.join(ans4,\n",
    "         ans5.OwnerUserId == ans4.OwnerUserId)\\\n",
    "    .filter(F.col('Veteran')==0)\\\n",
    "    .withColumn('AnswerCount',F.col('AnswerCount').cast('int'))\\\n",
    "    .withColumn('ViewCount',F.col('ViewCount').cast('int'))\\\n",
    "    .agg(F.avg(\"Score\").alias(\"avg_score\"), \\\n",
    "         F.avg(\"ViewCount\").alias(\"avg_view\"), \\\n",
    "         F.avg(\"AnswerCount\").alias(\"avg_ans\"), \\\n",
    "         F.avg(\"FavoriteCount\").alias(\"avg_fav\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "Your score: 1.0000\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "identify_veterans = {\n",
    "    \"vet_score\": 3.54370533260033,\n",
    "    \"vet_views\": 926.3982398239824,\n",
    "    \"vet_answers\": 1.2981298129812981,\n",
    "    \"vet_favorites\": 1.3001649257833974,\n",
    "    \"brief_score\": 2.100892857142857,\n",
    "    \"brief_views\": 553.4952533132813,\n",
    "    \"brief_answers\": 0.9706739355202557,\n",
    "    \"brief_favorites\": 0.5757988721804511\n",
    "}\n",
    "\n",
    "grader.score('spark__identify_veterans', identify_veterans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Identify veterans&mdash;full\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Same as above, but on the full Stack Exchange data set.\n",
    "\n",
    "No pre-parsed data is available for this question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "#### Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "* Total brief users: 1,848,628\n",
    "* Total veteran users: 288,285"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_lines_Full = sc.textFile('spark-stack-data/allPosts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_df_Full = post_lines_Full.filter(isRow) \\\n",
    "               .filter(lambda line : not isBadXML(line)) \\\n",
    "               .map(line_parser)\\\n",
    "               .toDF(sampleRatio=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_df_Full = post_df_Full.withColumn('FavoriteCount', \n",
    "                                F.when(F.col('FavoriteCount').isNull(), 0)\\\n",
    "                                 .otherwise(F.col('FavoriteCount').cast(IntegerType())))\\\n",
    "                    .withColumn('Score', \n",
    "                                F.when(F.col('Score').isNull(), 0)\\\n",
    "                                 .otherwise(F.col('Score').cast(IntegerType()))).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_lines_Full = sc.textFile('spark-stack-data/allUsers/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_Full = user_lines_Full.filter(isRow) \\\n",
    "                    .filter(lambda line : not isBadXML(line)) \\\n",
    "                    .map(line_parser)\\\n",
    "                    .toDF(sampleRatio=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnd_count = lambda cond : F.sum(F.when(cond, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df_Full = user_df_Full.withColumn('UserCreationDate', F.to_timestamp('CreationDate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_df_firstq_Full = post_df_Full.withColumn('PostCreationDate', F.to_timestamp('CreationDate'))\\\n",
    "                        .groupBy('OwnerUserId', 'PostTypeId')\\\n",
    "                        .agg((F.min('PostCreationDate')).alias('FirstPostDate')).alias('grouped')\\\n",
    "                        .filter(F.col('grouped.PostTypeId')=='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined2_Full= post_df_firstq_Full.join(user_df_Full,\n",
    "                             user_df_Full.Id == post_df_firstq_Full.OwnerUserId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_df_Full = post_df_Full.withColumn('PostCreationDate', F.to_timestamp('CreationDate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined3_Full = post_df_Full.join(user_df_Full,\n",
    "                    user_df_Full.Id == post_df_Full.OwnerUserId)\\\n",
    "                .withColumn('DiffinSec', F.col('PostCreationDate').cast('long') - \n",
    "                                        F.col('UserCreationDate').cast('long'))\\\n",
    "                .withColumn('DiffinDay', F.floor(F.col('DiffinSec')/3600/24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans3_Full = joined3_Full.withColumn('Veteran',\n",
    "            F.when((joined3_Full.DiffinDay < 150) & (joined3_Full.DiffinDay >=100), 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans4_Full = ans3_Full.groupby('OwnerUserId')\\\n",
    "            .agg(F.max('Veteran').alias('Veteran'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans5_Full = post_df_firstq_Full.join(post_df_Full.drop('OwnerUserId'),\n",
    "                           post_df_firstq_Full.FirstPostDate == post_df_Full.PostCreationDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+------------------+------------------+\n",
      "|         avg_score|          avg_view|           avg_ans|           avg_fav|\n",
      "+------------------+------------------+------------------+------------------+\n",
      "|2.2633363967407396|1843.8346396040747|1.8426235821987713|0.8659919479810351|\n",
      "+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ans5_Full.join(ans4_Full,\n",
    "         ans5_Full.OwnerUserId == ans4_Full.OwnerUserId)\\\n",
    "    .filter(F.col('Veteran')==1)\\\n",
    "    .withColumn('AnswerCount',F.col('AnswerCount').cast('int'))\\\n",
    "    .withColumn('ViewCount',F.col('ViewCount').cast('int'))\\\n",
    "    .agg(F.avg(\"Score\").alias(\"avg_score\"), \\\n",
    "         F.avg(\"ViewCount\").alias(\"avg_view\"), \\\n",
    "         F.avg(\"AnswerCount\").alias(\"avg_ans\"), \\\n",
    "         F.avg(\"FavoriteCount\").alias(\"avg_fav\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+------------------+------------------+\n",
      "|        avg_score|          avg_view|           avg_ans|           avg_fav|\n",
      "+-----------------+------------------+------------------+------------------+\n",
      "|1.132576795927856|1096.1792785068071|1.5038891466685484|0.3857949160857235|\n",
      "+-----------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ans5_Full.join(ans4_Full,\n",
    "         ans5_Full.OwnerUserId == ans4_Full.OwnerUserId)\\\n",
    "    .filter(F.col('Veteran')==0)\\\n",
    "    .withColumn('AnswerCount',F.col('AnswerCount').cast('int'))\\\n",
    "    .withColumn('ViewCount',F.col('ViewCount').cast('int'))\\\n",
    "    .agg(F.avg(\"Score\").alias(\"avg_score\"), \\\n",
    "         F.avg(\"ViewCount\").alias(\"avg_view\"), \\\n",
    "         F.avg(\"AnswerCount\").alias(\"avg_ans\"), \\\n",
    "         F.avg(\"FavoriteCount\").alias(\"avg_fav\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Word2vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Word2Vec is an alternative approach for vectorizing text data. The vectorized representations of words in the vocabulary tend to be useful for predicting other words in the document, hence the famous example \"vector('king') - vector('man') + vector('woman') ~= vector('queen')\".\n",
    "\n",
    "Let's see how good a Word2Vec model we can train using the **tags** of each Stack Exchange post as documents (this uses the full data set). Let's use the implementation of Word2Vec from Spark ML (this will require using DataFrames) to return a list of the top 25 closest synonyms to \"ggplot2\" and their similarity score in tuple format (\"string\", number).\n",
    "\n",
    "The tags appear in the data as one string, I will need to separate them into individual tags. There is no need to further parse them beyond separating them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "#### Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "The dimensionality of the vector space should be 100. The random seed should be 42 in `PySpark`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "#### Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "* Mean of the top 25 cosine similarities: 0.8012362027168274"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def findall_tagwords(s):\n",
    "    if s is None:\n",
    "        return []\n",
    "    wordlist = re.split(r'><',s)\n",
    "    return [word.replace(r'<','').replace(r'>','') for word in wordlist]\n",
    "\n",
    "findall_tagwords_udf = udf(findall_tagwords, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2Vec\n",
    "\n",
    "import re\n",
    "\n",
    "wordre = re.compile('[a-z]+')\n",
    "\n",
    "post_df_Full = post_df_Full.withColumn('Tagwords', findall_tagwords_udf(F.col('Tags')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(inputCol='Tagwords', outputCol='vectors', vectorSize=30, minCount=5, seed=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = w2v.fit(post_df_Full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transform(post_df_Full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "myresult = model.findSynonyms('ggplot2', 25).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec= list(zip(myresult.word[:25],myresult.similarity[:25]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "I'd like to see if we can predict the tags of a **question** from its body text. Instead of predicting specific tags, we will instead try to predict if a question contains one of the top ten most common tags.  \n",
    "\n",
    "To this end, I have separated out a train and a test set from the original data. The training and tests sets were downloaded with the stats data at the beginning of the notebook.  You can also get them from S3:\n",
    "  * `s3://dataincubator-course/spark-stats-data/posts_train.zip`\n",
    "  * `s3://dataincubator-course/spark-stats-data/posts_test.zip`\n",
    "\n",
    "This will involve two steps: first, to find the ten most common tags for questions in the training data set (the tags have been removed from the test set). Then to train a learner to predict from the text of the question (the `Body` attribute) if it should have one of those ten tags in it - you will need to process the question text with NLP techniques such as splitting the text into tokens.\n",
    "\n",
    "Since I can't reliably pickle Spark models, instead return a list of your predictions, sorted by the question's `Id`. This sorting is very important.\n",
    "\n",
    "As an example, if my top tags include `spark` and `python`, and we had the following questions:\n",
    "\n",
    "```\n",
    "<row Body=\"...\" Id=\"1740\" Tags=\"<machine-learning><spark><regression>\" ... />\n",
    "<row Body=\"...\" Id=\"723\" Tags=\"<statistics><neurons>\" ... />\n",
    "<row Body=\"...\" Id=\"2740\" Tags=\"<functional><python><spark><pyspark>\" ... />\n",
    "```\n",
    "\n",
    "I would expect to return `[0, 1, 1]` (for the order `[723, 1740, 2740]`).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "#### Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "- Number of training posts with a tag in the top 10: `22525`\n",
    "- Number without: `19540`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  spark-stats-data/posts_train.zip\n",
      "replace spark-stats-data/train/part-00001? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n",
      "Archive:  spark-stats-data/posts_test.zip\n",
      "replace spark-stats-data/test/part-00001? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!unzip -d spark-stats-data/train spark-stats-data/posts_train.zip\n",
    "!unzip -d spark-stats-data/test spark-stats-data/posts_test.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lines = sc.textFile('spark-stats-data/train/')\n",
    "test_lines = sc.textFile('spark-stats-data/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<?xml version=\"1.0\" encoding=\"UTF-8\"?>',\n",
       " '<parent>',\n",
       " '  <row Body=\"&lt;p&gt;A very well described question.  In mathematical terms we have two binomial populations:&lt;/p&gt;&#10;&#10;&lt;p&gt;$$x|npI\\\\sim bin(n,p)$$&lt;/p&gt;&#10;&#10;&lt;p&gt;$$y|mqI\\\\sim bin(m,q)$$&lt;/p&gt;&#10;&#10;&lt;p&gt;Where $x$ is the number of deaths in the control group with $n$ observations, $y$ is the number of deaths in the group of size $m$ which received the enhancer, and $I$ is the prior information - which includes the binomial assumption.  The hypothesis is that $q&amp;gt;p$.  The alternative which is most obvious is $q\\\\leq p$ (i.e. we are not quesitoning the binomial model).  I presume your &quot;naive&quot; approach is to consider $\\\\hat{p}=\\\\frac{x}{n}$ as fixed and then test if $q&amp;gt;\\\\hat{p}$ using the cummulative binomial distribution.&lt;/p&gt;&#10;&#10;&lt;p&gt;To do the test and account for the uncertainty in $p$, the best approach is to integrate them out using a prior distribution which describes what is known about them (independently of what the data tells you about them).  To do this we require the joint posterior for $p,q$.&lt;/p&gt;&#10;&#10;&lt;p&gt;$$p(pq|xynmI)\\\\propto p(pq|I)p(xy|pqnmI)$$&lt;/p&gt;&#10;&#10;&lt;p&gt;Now I think it is reasonable to suppose the likehood factors, as you have assumed a binomial distribution, which is conditionally independent.  So we have:&lt;/p&gt;&#10;&#10;&lt;p&gt;$$p(xy|nmpqI)\\\\propto p^{x}(1-p)^{n-x}q^{y}(1-q)^{m-y}$$&lt;/p&gt;&#10;&#10;&lt;p&gt;Now because you have a large $n$ then the particular prior used won\\'t matter unless it is quite strong.  Assuming this is the case, then we can use a uniform prior $p(p|I)=1$.  However we also require the conditonal prior $p(q|pI)$.  This is likely to be non-uniform, but as before unless it is on the order of $m$ (i.e an $m$ degree polynomial) it won\\'t be able to greatly affect the result.  So i will use a flat prior also.  This means the posterior is proportional to the likelihood which is is the product of two beta distributions.  The probability we are after is given by:&lt;/p&gt;&#10;&#10;&lt;p&gt;$$Pr(q&amp;gt;p|xynmI)=\\\\frac{']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lines.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_lines.filter(isRow) \\\n",
    "               .filter(lambda line : not isBadXML(line)) \\\n",
    "               .map(line_parser)\\\n",
    "               .toDF(sampleRatio=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.withColumn('Tagwords', findall_tagwords_udf(F.col('Tags')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|PostTypeId|\n",
      "+----------+\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         1|\n",
      "|         2|\n",
      "|         1|\n",
      "|         1|\n",
      "|         2|\n",
      "|         2|\n",
      "|         1|\n",
      "|         2|\n",
      "|         1|\n",
      "|         1|\n",
      "|         2|\n",
      "|         1|\n",
      "|         5|\n",
      "|         4|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         1|\n",
      "|         2|\n",
      "|         2|\n",
      "|         5|\n",
      "|         4|\n",
      "|         2|\n",
      "|         2|\n",
      "|         1|\n",
      "|         2|\n",
      "|         1|\n",
      "|         2|\n",
      "|         1|\n",
      "|         2|\n",
      "|         1|\n",
      "|         2|\n",
      "|         2|\n",
      "|         1|\n",
      "|         2|\n",
      "|         1|\n",
      "|         1|\n",
      "|         1|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         1|\n",
      "|         1|\n",
      "|         2|\n",
      "|         1|\n",
      "|         1|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         1|\n",
      "|         2|\n",
      "|         1|\n",
      "|         2|\n",
      "|         1|\n",
      "|         1|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         1|\n",
      "|         1|\n",
      "|         5|\n",
      "|         4|\n",
      "|         1|\n",
      "|         2|\n",
      "|         1|\n",
      "|         2|\n",
      "|         2|\n",
      "|         1|\n",
      "|         1|\n",
      "|         2|\n",
      "|         2|\n",
      "|         1|\n",
      "|         1|\n",
      "|         1|\n",
      "|         1|\n",
      "|         1|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         1|\n",
      "|         1|\n",
      "|         1|\n",
      "|         1|\n",
      "|         2|\n",
      "|         1|\n",
      "|         2|\n",
      "|         1|\n",
      "|         2|\n",
      "|         2|\n",
      "|         1|\n",
      "+----------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.select(['PostTypeId']).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_qs = train_df.filter(F.col('PostTypeId')=='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42065"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_qs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89357"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = train_df_qs.select(F.explode('Tagwords').alias('col')).groupBy('col').count().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(col='interaction', count=512),\n",
       " Row(col='online', count=54),\n",
       " Row(col='overdispersion', count=44),\n",
       " Row(col='likelihood', count=120),\n",
       " Row(col='clogit', count=18),\n",
       " Row(col='clustered-standard-errors', count=33),\n",
       " Row(col='counterbalancing', count=6),\n",
       " Row(col='distributions', count=1807),\n",
       " Row(col='prediction-limit', count=6),\n",
       " Row(col='cohens-d', count=28),\n",
       " Row(col='gini', count=17),\n",
       " Row(col='nlme', count=43),\n",
       " Row(col='uninformative-prior', count=13),\n",
       " Row(col='anosim', count=2),\n",
       " Row(col='intercept', count=28),\n",
       " Row(col='chemistry', count=1),\n",
       " Row(col='geometric-mean', count=1),\n",
       " Row(col='repeatability', count=10),\n",
       " Row(col='contrasts', count=80),\n",
       " Row(col='logistic', count=1627),\n",
       " Row(col='gaussian-mixture', count=100),\n",
       " Row(col='confirmatory-factor', count=67),\n",
       " Row(col='residual-analysis', count=28),\n",
       " Row(col='dag', count=5),\n",
       " Row(col='gamm4', count=7),\n",
       " Row(col='statistical-bias', count=6),\n",
       " Row(col='stochastic-ordering', count=2),\n",
       " Row(col='neuroimaging', count=7),\n",
       " Row(col='truncation', count=38),\n",
       " Row(col='image-processing', count=99),\n",
       " Row(col='mediation', count=68),\n",
       " Row(col='boxplot', count=60),\n",
       " Row(col='astronomy', count=1),\n",
       " Row(col='sphericity', count=18),\n",
       " Row(col='e1071', count=15),\n",
       " Row(col='fishersexact', count=83),\n",
       " Row(col='paired-comparisons', count=92),\n",
       " Row(col='geometry', count=17),\n",
       " Row(col='gwas', count=4),\n",
       " Row(col='trimmed-mean', count=12),\n",
       " Row(col='forecast', count=29),\n",
       " Row(col='big-data', count=26),\n",
       " Row(col='overfitting', count=64),\n",
       " Row(col='random-variable', count=309),\n",
       " Row(col='unbiased-estimator', count=125),\n",
       " Row(col='mutual-information', count=79),\n",
       " Row(col='odds-ratio', count=103),\n",
       " Row(col='effect-size', count=179),\n",
       " Row(col='importance-sampling', count=24),\n",
       " Row(col='open-bugs', count=12),\n",
       " Row(col='heuristic', count=3),\n",
       " Row(col='normal-distribution', count=1136),\n",
       " Row(col='forecasting', count=645),\n",
       " Row(col='latin-square', count=7),\n",
       " Row(col='unit-information-prior', count=2),\n",
       " Row(col='pooling', count=36),\n",
       " Row(col='local-statistics', count=3),\n",
       " Row(col='jaccard-similarity', count=3),\n",
       " Row(col='lsmc', count=1),\n",
       " Row(col='maximum-likelihood', count=578),\n",
       " Row(col='descriptive-statistics', count=154),\n",
       " Row(col='moments', count=99),\n",
       " Row(col='gls', count=35),\n",
       " Row(col='metropolis-hastings', count=60),\n",
       " Row(col='quotation', count=4),\n",
       " Row(col='spss', count=794),\n",
       " Row(col='compression', count=12),\n",
       " Row(col='dendrogram', count=19),\n",
       " Row(col='yates-correction', count=5),\n",
       " Row(col='survival', count=497),\n",
       " Row(col='psychometrics', count=142),\n",
       " Row(col='self-organizing-maps', count=27),\n",
       " Row(col='nominal', count=45),\n",
       " Row(col='kendall-tau', count=18),\n",
       " Row(col='scales', count=159),\n",
       " Row(col='combination', count=46),\n",
       " Row(col='cdf', count=130),\n",
       " Row(col='kernel', count=203),\n",
       " Row(col='random-effects-model', count=270),\n",
       " Row(col='notation', count=86),\n",
       " Row(col='smallareaestimation', count=1),\n",
       " Row(col='identifiability', count=29),\n",
       " Row(col='pitch-game', count=2),\n",
       " Row(col='google-spreadsheet', count=2),\n",
       " Row(col='dummy-variables', count=3),\n",
       " Row(col='finance', count=115),\n",
       " Row(col='units', count=15),\n",
       " Row(col='autoencoders', count=15),\n",
       " Row(col='fisher-transform', count=6),\n",
       " Row(col='k-nearest-neighbour', count=107),\n",
       " Row(col='scikit-learn', count=110),\n",
       " Row(col='dirichlet-distribution', count=75),\n",
       " Row(col='phd', count=3),\n",
       " Row(col='error-propagation', count=60),\n",
       " Row(col='kmodes', count=1),\n",
       " Row(col='gradient', count=5),\n",
       " Row(col='model-selection', count=494),\n",
       " Row(col='sandwich', count=7),\n",
       " Row(col='pcoa', count=5),\n",
       " Row(col='engineering-statistics', count=3),\n",
       " Row(col='gmmboost', count=1),\n",
       " Row(col='inverse-gamma', count=17),\n",
       " Row(col='bootstrap', count=456),\n",
       " Row(col='spatial-interaction-model', count=5),\n",
       " Row(col='conjoint-analysis', count=22),\n",
       " Row(col='piecewise-linear', count=20),\n",
       " Row(col='code', count=34),\n",
       " Row(col='type-i-errors', count=44),\n",
       " Row(col='mgcv', count=28),\n",
       " Row(col='lrt', count=6),\n",
       " Row(col='schoenfeld-residuals', count=1),\n",
       " Row(col='calc', count=2),\n",
       " Row(col='monitoring', count=2),\n",
       " Row(col='panel-data', count=330),\n",
       " Row(col='composite', count=34),\n",
       " Row(col='optimal-stopping', count=12),\n",
       " Row(col='quasi-likelihood', count=15),\n",
       " Row(col='students-t', count=17),\n",
       " Row(col='moving-average', count=28),\n",
       " Row(col='control-chart', count=24),\n",
       " Row(col='pca', count=676),\n",
       " Row(col='signal-processing', count=91),\n",
       " Row(col='standard-deviation', count=451),\n",
       " Row(col='finite-population', count=31),\n",
       " Row(col='medicine', count=1),\n",
       " Row(col='variance-test', count=2),\n",
       " Row(col='curves', count=19),\n",
       " Row(col='likelihood-ratio', count=123),\n",
       " Row(col='general-additive-model', count=4),\n",
       " Row(col='rayleigh', count=7),\n",
       " Row(col='wlln', count=6),\n",
       " Row(col='credible-interval', count=26),\n",
       " Row(col='power', count=157),\n",
       " Row(col='underdetermined', count=9),\n",
       " Row(col='agreement-statistics', count=7),\n",
       " Row(col='expected-value', count=272),\n",
       " Row(col='population', count=121),\n",
       " Row(col='libsvm', count=128),\n",
       " Row(col='pattern-recognition', count=143),\n",
       " Row(col='binning', count=36),\n",
       " Row(col='lm', count=70),\n",
       " Row(col='ronald-fisher', count=2),\n",
       " Row(col='machine-learning', count=2524),\n",
       " Row(col='latent-class', count=27),\n",
       " Row(col='reproducible-research', count=17),\n",
       " Row(col='glmer', count=61),\n",
       " Row(col='hierarchical-bayesian', count=104),\n",
       " Row(col='mixed-distribution', count=1),\n",
       " Row(col='stepwise-regression', count=78),\n",
       " Row(col='trend', count=105),\n",
       " Row(col='hierarchical', count=70),\n",
       " Row(col='log-likelihood', count=3),\n",
       " Row(col='sources', count=3),\n",
       " Row(col='twin', count=8),\n",
       " Row(col='arch', count=14),\n",
       " Row(col='r-project', count=1),\n",
       " Row(col='data-cleaning', count=24),\n",
       " Row(col='segmentation', count=25),\n",
       " Row(col='nlmer', count=3),\n",
       " Row(col='neweywest', count=9),\n",
       " Row(col='inverse-gaussian-distrib', count=4),\n",
       " Row(col='choice', count=11),\n",
       " Row(col='hypothesis-testing', count=1926),\n",
       " Row(col='sweave', count=7),\n",
       " Row(col='non-central', count=11),\n",
       " Row(col='traminer', count=39),\n",
       " Row(col='scale-invariance', count=12),\n",
       " Row(col='k-means', count=224),\n",
       " Row(col='convolution', count=47),\n",
       " Row(col='nonparametric-density', count=3),\n",
       " Row(col='project-management', count=9),\n",
       " Row(col='outliers', count=316),\n",
       " Row(col='lme', count=102),\n",
       " Row(col='unit-root', count=57),\n",
       " Row(col='hypergeometric', count=50),\n",
       " Row(col='dyadic-data', count=6),\n",
       " Row(col='delta-method', count=29),\n",
       " Row(col='scipy', count=45),\n",
       " Row(col='discriminant', count=13),\n",
       " Row(col='covariate', count=42),\n",
       " Row(col='cox-model', count=223),\n",
       " Row(col='skewness', count=145),\n",
       " Row(col='education', count=36),\n",
       " Row(col='consistency', count=55),\n",
       " Row(col='duan-smearing', count=1),\n",
       " Row(col='mixed', count=36),\n",
       " Row(col='gretl', count=3),\n",
       " Row(col='polling', count=16),\n",
       " Row(col='augmented-dickey-fuller', count=14),\n",
       " Row(col='scatterplot', count=71),\n",
       " Row(col='winbugs', count=62),\n",
       " Row(col='random-matrix', count=16),\n",
       " Row(col='bonferroni', count=54),\n",
       " Row(col='interval', count=56),\n",
       " Row(col='imputation', count=4),\n",
       " Row(col='data-visualization', count=948),\n",
       " Row(col='roc', count=174),\n",
       " Row(col='method-of-moments', count=34),\n",
       " Row(col='gam', count=86),\n",
       " Row(col='out-of-sample', count=33),\n",
       " Row(col='sentiment-analysis', count=9),\n",
       " Row(col='variability', count=23),\n",
       " Row(col='sequential-analysis', count=30),\n",
       " Row(col='pivot-table', count=3),\n",
       " Row(col='distance-functions', count=144),\n",
       " Row(col='teaching', count=72),\n",
       " Row(col='non-response', count=16),\n",
       " Row(col='philosophical', count=34),\n",
       " Row(col='mice', count=20),\n",
       " Row(col='rlm', count=4),\n",
       " Row(col='difference-in-difference', count=34),\n",
       " Row(col='multiple-imputation', count=105),\n",
       " Row(col='terminology', count=218),\n",
       " Row(col='power-law', count=52),\n",
       " Row(col='logarithm', count=80),\n",
       " Row(col='macroeconomics', count=14),\n",
       " Row(col='absolute-risk', count=3),\n",
       " Row(col='pareto-distribution', count=37),\n",
       " Row(col='filter', count=35),\n",
       " Row(col='geostatistics', count=18),\n",
       " Row(col='test-for-trend', count=5),\n",
       " Row(col='tobit-regression', count=37),\n",
       " Row(col='matching', count=65),\n",
       " Row(col='poisson-process', count=61),\n",
       " Row(col='chemometrics', count=11),\n",
       " Row(col='down-sample', count=3),\n",
       " Row(col='genetic-algorithms', count=48),\n",
       " Row(col='multivariate-regression', count=78),\n",
       " Row(col='vif', count=23),\n",
       " Row(col='summations', count=18),\n",
       " Row(col='c#', count=12),\n",
       " Row(col='mathematica', count=16),\n",
       " Row(col='elicitation', count=6),\n",
       " Row(col='semiparametric', count=6),\n",
       " Row(col='poisson', count=474),\n",
       " Row(col='epidemiology', count=116),\n",
       " Row(col='rapidminer', count=18),\n",
       " Row(col='fourier-transform', count=33),\n",
       " Row(col='partial', count=13),\n",
       " Row(col='deep-learning', count=89),\n",
       " Row(col='age-period-cohort', count=2),\n",
       " Row(col='intraclass-correlation', count=74),\n",
       " Row(col='covariance', count=323),\n",
       " Row(col='randomization', count=46),\n",
       " Row(col='computer-vision', count=23),\n",
       " Row(col='checking', count=9),\n",
       " Row(col='arma', count=119),\n",
       " Row(col='degrees-of-freedom', count=101),\n",
       " Row(col='range', count=5),\n",
       " Row(col='average', count=147),\n",
       " Row(col='nonparametric', count=519),\n",
       " Row(col='proof', count=103),\n",
       " Row(col='open-source', count=11),\n",
       " Row(col='library', count=12),\n",
       " Row(col='factorisation-theorem', count=1),\n",
       " Row(col='jags', count=114),\n",
       " Row(col='power-analysis', count=192),\n",
       " Row(col='optimal-scaling', count=18),\n",
       " Row(col='contingency-tables', count=125),\n",
       " Row(col='poisson-regression', count=90),\n",
       " Row(col='rocr', count=2),\n",
       " Row(col='bounds', count=45),\n",
       " Row(col='moving-window', count=14),\n",
       " Row(col='error-in-variables', count=5),\n",
       " Row(col='factor-analysis', count=353),\n",
       " Row(col='random-generation', count=193),\n",
       " Row(col='kurtosis', count=56),\n",
       " Row(col='convergence', count=154),\n",
       " Row(col='bernoulli-distribution', count=65),\n",
       " Row(col='naive-bayes', count=159),\n",
       " Row(col='programming', count=18),\n",
       " Row(col='condition-number', count=1),\n",
       " Row(col='fixed-effects-model', count=157),\n",
       " Row(col='paradox', count=15),\n",
       " Row(col='information-theory', count=107),\n",
       " Row(col='multivariable', count=26),\n",
       " Row(col='skew-normal', count=6),\n",
       " Row(col='bernoulli-process', count=4),\n",
       " Row(col='mcmc', count=303),\n",
       " Row(col='operations-research', count=9),\n",
       " Row(col='linear-model', count=481),\n",
       " Row(col='psychology', count=46),\n",
       " Row(col='perl', count=2),\n",
       " Row(col='population-average', count=2),\n",
       " Row(col='small-sample', count=153),\n",
       " Row(col='particle-filter', count=18),\n",
       " Row(col='linear-mixed-model', count=3),\n",
       " Row(col='inference', count=298),\n",
       " Row(col='sampling', count=718),\n",
       " Row(col='measurement', count=86),\n",
       " Row(col='excel', count=178),\n",
       " Row(col='seasonality', count=104),\n",
       " Row(col='gibbs', count=88),\n",
       " Row(col='dice', count=43),\n",
       " Row(col='minimum', count=33),\n",
       " Row(col='dependence', count=15),\n",
       " Row(col='vecm', count=24),\n",
       " Row(col='heavy-tailed', count=8),\n",
       " Row(col='lognormal', count=122),\n",
       " Row(col='ggplot2', count=74),\n",
       " Row(col='moderator', count=8),\n",
       " Row(col='reporting', count=56),\n",
       " Row(col='cv.glm', count=3),\n",
       " Row(col='recursive-model', count=6),\n",
       " Row(col='rbm', count=51),\n",
       " Row(col='extremal-dependence', count=3),\n",
       " Row(col='polynomial', count=62),\n",
       " Row(col='discontinuity', count=16),\n",
       " Row(col='model', count=250),\n",
       " Row(col='lags', count=38),\n",
       " Row(col='bias', count=164),\n",
       " Row(col='gnuplot', count=6),\n",
       " Row(col='familywise-error', count=8),\n",
       " Row(col='splus', count=3),\n",
       " Row(col='state-space-models', count=42),\n",
       " Row(col='database', count=14),\n",
       " Row(col='predictor', count=94),\n",
       " Row(col='decision-theory', count=65),\n",
       " Row(col='threshold', count=39),\n",
       " Row(col='numpy', count=18),\n",
       " Row(col='arithmetic', count=35),\n",
       " Row(col='simpsons-paradox', count=13),\n",
       " Row(col='qq-plot', count=58),\n",
       " Row(col='rank-correlation', count=40),\n",
       " Row(col='mse', count=40),\n",
       " Row(col='population-ecology', count=3),\n",
       " Row(col='frequency-severity', count=3),\n",
       " Row(col='optimal', count=4),\n",
       " Row(col='causal-inference', count=140),\n",
       " Row(col='auc', count=64),\n",
       " Row(col='dunn-test', count=7),\n",
       " Row(col='matrix-decomposition', count=62),\n",
       " Row(col='starting-values', count=5),\n",
       " Row(col='experiment-design', count=383),\n",
       " Row(col='kalman-filter', count=91),\n",
       " Row(col='stationarity', count=142),\n",
       " Row(col='funnel-plot', count=11),\n",
       " Row(col='non-stationary', count=36),\n",
       " Row(col='precision-recall', count=98),\n",
       " Row(col='cross-correlation', count=84),\n",
       " Row(col='clinical-trials', count=54),\n",
       " Row(col='gumbel', count=8),\n",
       " Row(col='parallel-computing', count=16),\n",
       " Row(col='large-data', count=146),\n",
       " Row(col='wishart', count=23),\n",
       " Row(col='oversampling', count=15),\n",
       " Row(col='type-ii-errors', count=18),\n",
       " Row(col='qualitative', count=7),\n",
       " Row(col='bayesian-network', count=28),\n",
       " Row(col='taylor-series', count=4),\n",
       " Row(col='jeffreys-prior', count=3),\n",
       " Row(col='beta-binomial', count=33),\n",
       " Row(col='ruby', count=6),\n",
       " Row(col='manova', count=123),\n",
       " Row(col='social-network', count=39),\n",
       " Row(col='neural-networks', count=543),\n",
       " Row(col='text-mining', count=234),\n",
       " Row(col='assumptions', count=205),\n",
       " Row(col='generative-models', count=22),\n",
       " Row(col='impulse-response', count=5),\n",
       " Row(col='software', count=122),\n",
       " Row(col='repeated-measures', count=736),\n",
       " Row(col='spearman', count=69),\n",
       " Row(col='package', count=19),\n",
       " Row(col='validity', count=41),\n",
       " Row(col='discrete-data', count=144),\n",
       " Row(col='svd', count=117),\n",
       " Row(col='careers', count=20),\n",
       " Row(col='crossover-study', count=5),\n",
       " Row(col='gamboost', count=2),\n",
       " Row(col='sample-size', count=429),\n",
       " Row(col='density', count=44),\n",
       " Row(col='index-decomposition', count=11),\n",
       " Row(col='causality', count=5),\n",
       " Row(col='conferences', count=5),\n",
       " Row(col='np', count=2),\n",
       " Row(col='spatio-temporal', count=30),\n",
       " Row(col='tukey-hsd', count=40),\n",
       " Row(col='loess', count=30),\n",
       " Row(col='maximum', count=48),\n",
       " Row(col='fractional-factorial', count=14),\n",
       " Row(col='f-statistic', count=9),\n",
       " Row(col='ranks', count=33),\n",
       " Row(col='job', count=6),\n",
       " Row(col='multivariate-analysis', count=610),\n",
       " Row(col='errors-in-variables', count=10),\n",
       " Row(col='knowledge-discovery', count=4),\n",
       " Row(col='generilzed-linear-model', count=1),\n",
       " Row(col='noise', count=15),\n",
       " Row(col='time-complexity', count=6),\n",
       " Row(col='total-least-squares', count=1),\n",
       " Row(col='copula', count=67),\n",
       " Row(col='heteroscedasticity', count=256),\n",
       " Row(col='learning', count=57),\n",
       " Row(col='marketing', count=19),\n",
       " Row(col='fat-tails', count=16),\n",
       " Row(col='regularization', count=137),\n",
       " Row(col='median', count=128),\n",
       " Row(col='glmmlasso', count=2),\n",
       " Row(col='social-science', count=17),\n",
       " Row(col='correlated-predictors', count=12),\n",
       " Row(col='variance-covariance', count=125),\n",
       " Row(col='control', count=18),\n",
       " Row(col='tweedie-distribution', count=5),\n",
       " Row(col='summary-statistics', count=185),\n",
       " Row(col='var', count=76),\n",
       " Row(col='adjustment', count=20),\n",
       " Row(col='value-of-information', count=6),\n",
       " Row(col='inferential-statistics', count=21),\n",
       " Row(col='data-generating-process', count=8),\n",
       " Row(col='marginal', count=78),\n",
       " Row(col='shrinkage', count=32),\n",
       " Row(col='singular', count=4),\n",
       " Row(col='plyr', count=2),\n",
       " Row(col='feature-selection', count=447),\n",
       " Row(col='weighted-sampling', count=84),\n",
       " Row(col='change-point', count=64),\n",
       " Row(col='coefficient', count=41),\n",
       " Row(col='xorshift', count=2),\n",
       " Row(col='basic-concepts', count=148),\n",
       " Row(col='coefficient-of-variation', count=28),\n",
       " Row(col='jackknife', count=10),\n",
       " Row(col='non-inferiority', count=3),\n",
       " Row(col='fisher', count=46),\n",
       " Row(col='prediction', count=359),\n",
       " Row(col='big-list', count=30),\n",
       " Row(col='zero-inflation', count=82),\n",
       " Row(col='in-sample', count=4),\n",
       " Row(col='poisson-binomial', count=9),\n",
       " Row(col='derivative', count=2),\n",
       " Row(col='explanatory-models', count=2),\n",
       " Row(col='count-data', count=176),\n",
       " Row(col='dimensionality-reduction', count=176),\n",
       " Row(col='statistical-learning', count=37),\n",
       " Row(col='two-step-estimation', count=12),\n",
       " Row(col='contrast', count=3),\n",
       " Row(col='probabilistic-programming', count=8),\n",
       " Row(col='mlogit', count=11),\n",
       " Row(col='negative-binomial', count=162),\n",
       " Row(col='2sls', count=14),\n",
       " Row(col='kaplan-meier', count=41),\n",
       " Row(col='javascript', count=7),\n",
       " Row(col='random-walk', count=30),\n",
       " Row(col='accuracy', count=40),\n",
       " Row(col='mars', count=1),\n",
       " Row(col='best-practices', count=47),\n",
       " Row(col='canonical-correlation', count=26),\n",
       " Row(col='path-model', count=24),\n",
       " Row(col='censoring', count=80),\n",
       " Row(col='ancova', count=162),\n",
       " Row(col='intervention-analysis', count=31),\n",
       " Row(col='subset', count=20),\n",
       " Row(col='ordinal', count=303),\n",
       " Row(col='quantiles', count=141),\n",
       " Row(col='f-test', count=69),\n",
       " Row(col='numerical-integration', count=26),\n",
       " Row(col='regression-to-the-mean', count=6),\n",
       " Row(col='radial-basis', count=8),\n",
       " Row(col='cochran-armitage-test', count=2),\n",
       " Row(col='sql', count=14),\n",
       " Row(col='asymptotics', count=91),\n",
       " Row(col='train', count=40),\n",
       " Row(col='politics', count=4),\n",
       " Row(col='rmr', count=2),\n",
       " Row(col='confidence-interval', count=932),\n",
       " Row(col='aggregation', count=55),\n",
       " Row(col='climate', count=8),\n",
       " Row(col='kernel-trick', count=60),\n",
       " Row(col='games', count=56),\n",
       " Row(col='biplot', count=16),\n",
       " Row(col='rare-events', count=28),\n",
       " Row(col='deep-belief-networks', count=40),\n",
       " Row(col='rms', count=35),\n",
       " Row(col='conditional-expectation', count=112),\n",
       " Row(col='garch', count=111),\n",
       " Row(col='rjags', count=29),\n",
       " Row(col='variance-decomposition', count=5),\n",
       " Row(col='regression-coefficients', count=270),\n",
       " Row(col='inter-rater', count=71),\n",
       " Row(col='confidence-distribution', count=6),\n",
       " Row(col='hac', count=3),\n",
       " Row(col='multi-class', count=65),\n",
       " Row(col='nonlinear', count=74),\n",
       " Row(col='dataset', count=480),\n",
       " Row(col='ranking', count=155),\n",
       " Row(col='uncertainty', count=71),\n",
       " Row(col='splines', count=88),\n",
       " Row(col='geomarketing', count=2),\n",
       " Row(col='reliability', count=164),\n",
       " Row(col='empirical', count=41),\n",
       " Row(col='history', count=40),\n",
       " Row(col='k-medoids', count=8),\n",
       " Row(col='conditional-probability', count=370),\n",
       " Row(col='jmp', count=25),\n",
       " Row(col='science', count=7),\n",
       " Row(col='igraph', count=8),\n",
       " Row(col='regression', count=5408),\n",
       " Row(col='ordered-logit', count=22),\n",
       " Row(col='environmental-data', count=6),\n",
       " Row(col='discussion', count=4),\n",
       " Row(col='point-mass-at-zero', count=3),\n",
       " Row(col='planned-comparisons-test', count=7),\n",
       " Row(col='data-transformation', count=556),\n",
       " Row(col='directional-statistics', count=14),\n",
       " Row(col='runs', count=1),\n",
       " Row(col='pca-regression', count=3),\n",
       " Row(col='unbalanced-classes', count=105),\n",
       " Row(col='case-control-study', count=32),\n",
       " Row(col='cholesky', count=8),\n",
       " Row(col='gllamm', count=7),\n",
       " Row(col='categorical-data', count=835),\n",
       " Row(col='frequentist', count=70),\n",
       " Row(col='gbm', count=55),\n",
       " Row(col='f-distribution', count=22),\n",
       " Row(col='sample-mean', count=30),\n",
       " Row(col='model-based-clustering', count=22),\n",
       " Row(col='multiple-regression', count=878),\n",
       " Row(col='robust', count=159),\n",
       " Row(col='multicollinearity', count=212),\n",
       " Row(col='interquartile', count=4),\n",
       " Row(col='specificity', count=17),\n",
       " Row(col='books', count=152),\n",
       " Row(col='binary-data', count=188),\n",
       " Row(col='mathematics', count=41),\n",
       " Row(col='media', count=9),\n",
       " Row(col='interval-censoring', count=16),\n",
       " Row(col='test-equating', count=2),\n",
       " Row(col='stacking', count=4),\n",
       " Row(col='beta', count=34),\n",
       " Row(col='missing-data', count=340),\n",
       " Row(col='feature-construction', count=62),\n",
       " Row(col='natural-language', count=57),\n",
       " Row(col='nls', count=23),\n",
       " Row(col='loss-functions', count=54),\n",
       " Row(col='expectation-maximization', count=101),\n",
       " Row(col='matrix-inverse', count=33),\n",
       " Row(col='histogram', count=138),\n",
       " Row(col='bayes-network', count=60),\n",
       " Row(col='numerics', count=25),\n",
       " Row(col='life-expectancy', count=6),\n",
       " Row(col='neuroscience', count=1),\n",
       " Row(col='granger-causality', count=34),\n",
       " Row(col='instrumental-variables', count=86),\n",
       " Row(col='failure', count=12),\n",
       " Row(col='fdr', count=45),\n",
       " Row(col='stan', count=23),\n",
       " Row(col='manifold-learning', count=5),\n",
       " Row(col='predictive-models', count=578),\n",
       " Row(col='multinomial', count=247),\n",
       " Row(col='caret', count=93),\n",
       " Row(col='tolerance-interval', count=12),\n",
       " Row(col='linear-dynamical-system', count=6),\n",
       " Row(col='fuzzy-set', count=9),\n",
       " Row(col='resources', count=9),\n",
       " Row(col='tost', count=7),\n",
       " Row(col='qsar', count=1),\n",
       " Row(col='dispersion', count=13),\n",
       " Row(col='chi-distribution', count=1),\n",
       " Row(col='bugs', count=85),\n",
       " Row(col='graph-theory', count=83),\n",
       " Row(col='odds', count=23),\n",
       " Row(col='parallel-analysis', count=5),\n",
       " Row(col='mancova', count=1),\n",
       " Row(col='deming-regression', count=6),\n",
       " Row(col='measurement-error', count=125),\n",
       " Row(col='networks', count=66),\n",
       " Row(col='lme4', count=114),\n",
       " Row(col='hyperparameter', count=31),\n",
       " Row(col='gambling', count=2),\n",
       " Row(col='courses', count=4),\n",
       " Row(col='cluster-sample', count=30),\n",
       " Row(col='classification-tree', count=46),\n",
       " Row(col='mcnemar-test', count=28),\n",
       " Row(col='jacobian', count=2),\n",
       " Row(col='tikhonov', count=1),\n",
       " Row(col='joint-distribution', count=111),\n",
       " Row(col='mean', count=439),\n",
       " Row(col='dlm', count=19),\n",
       " Row(col='fuzzy', count=20),\n",
       " Row(col='sensitivity', count=27),\n",
       " Row(col='chi-squared', count=594),\n",
       " Row(col='hidden-markov-model', count=174),\n",
       " Row(col='resampling', count=90),\n",
       " Row(col='bic', count=56),\n",
       " Row(col='bioinformatics', count=73),\n",
       " Row(col='matplotlib', count=11),\n",
       " Row(col='time-varying-covariate', count=31),\n",
       " Row(col='method-comparison', count=35),\n",
       " Row(col='structural-change', count=27),\n",
       " Row(col='latent-semantic-indexing', count=2),\n",
       " Row(col='monte-carlo', count=224),\n",
       " Row(col='constrained-regression', count=22),\n",
       " Row(col='elections', count=5),\n",
       " Row(col='modeling', count=590),\n",
       " Row(col='time-series', count=2654),\n",
       " Row(col='variance', count=746),\n",
       " Row(col='function', count=40),\n",
       " Row(col='chow-test', count=15),\n",
       " Row(col='confusion-matrix', count=24),\n",
       " Row(col='stochastic-approximation', count=2),\n",
       " Row(col='goodness-of-fit', count=286),\n",
       " Row(col='sparse', count=63),\n",
       " Row(col='glmnet', count=85),\n",
       " Row(col='multivariate', count=41),\n",
       " Row(col='pdf', count=310),\n",
       " Row(col='recommender-system', count=107),\n",
       " Row(col='ridge-regression', count=110),\n",
       " Row(col='within-subjects', count=11),\n",
       " Row(col='scoring', count=35),\n",
       " Row(col='deviance', count=39),\n",
       " Row(col='ordered-variables', count=20),\n",
       " Row(col='sign-test', count=10),\n",
       " Row(col='consulting', count=1),\n",
       " Row(col='diagnostic', count=61),\n",
       " Row(col='cart', count=256),\n",
       " Row(col='partitioning', count=39),\n",
       " Row(col='c++', count=23),\n",
       " Row(col='age', count=8),\n",
       " Row(col='internet', count=7),\n",
       " Row(col='bayesian-score', count=3),\n",
       " Row(col='statistical-control', count=23),\n",
       " Row(col='hazard', count=62),\n",
       " Row(col='model-comparison', count=90),\n",
       " Row(col='profile-likelihood', count=18),\n",
       " Row(col='confidence', count=55),\n",
       " Row(col='vowpal-wabbit', count=8),\n",
       " Row(col='proportion', count=247),\n",
       " Row(col='logit', count=180),\n",
       " Row(col='probability-inequalities', count=48),\n",
       " Row(col='spearman-rho', count=38),\n",
       " Row(col='ecdf', count=7),\n",
       " Row(col='order', count=3),\n",
       " Row(col='hessian', count=1),\n",
       " Row(col='novelty-detection', count=3),\n",
       " Row(col='fortran', count=1),\n",
       " Row(col='ram', count=1),\n",
       " Row(col='lars', count=16),\n",
       " Row(col='computing', count=25),\n",
       " Row(col='continuous-data', count=148),\n",
       " Row(col='quasi-monte-carlo', count=8),\n",
       " Row(col='beta-regression', count=22),\n",
       " Row(col='weka', count=92),\n",
       " Row(col='kappa', count=35),\n",
       " Row(col='mixed-effect', count=160),\n",
       " Row(col='information-geometry', count=4),\n",
       " Row(col='meta-regression', count=25),\n",
       " Row(col='autoregressive', count=136),\n",
       " Row(col='spatial', count=223),\n",
       " Row(col='ecology', count=28),\n",
       " Row(col='rotation', count=20),\n",
       " Row(col='irls', count=2),\n",
       " Row(col='breusch-pagan', count=3),\n",
       " Row(col='clpc', count=1),\n",
       " Row(col='quality-control', count=35),\n",
       " Row(col='algorithms', count=272),\n",
       " Row(col='exponential', count=130),\n",
       " Row(col='bestglm', count=1),\n",
       " Row(col='regression-strategy', count=1),\n",
       " Row(col='svm', count=668),\n",
       " Row(col='likelihood-function', count=74),\n",
       " Row(col='timelines', count=2),\n",
       " Row(col='cauchy', count=8),\n",
       " Row(col='theory', count=73),\n",
       " Row(col='bagging', count=24),\n",
       " Row(col='references', count=424),\n",
       " Row(col='integral', count=41),\n",
       " Row(col='multidimensional-scaling', count=73),\n",
       " Row(col='martingale', count=6),\n",
       " Row(col='scale-estimator', count=1),\n",
       " Row(col='metric', count=55),\n",
       " Row(col='mathematical-statistics', count=905),\n",
       " Row(col='treatment-effect', count=43),\n",
       " Row(col='sem', count=190),\n",
       " Row(col='visual-summary', count=1),\n",
       " Row(col='volatility-forecasting', count=24),\n",
       " Row(col='geometric-distribution', count=16),\n",
       " Row(col='logrank', count=17),\n",
       " Row(col='barplot', count=21),\n",
       " Row(col='white-noise', count=29),\n",
       " Row(col='kernel-density-estimate', count=46),\n",
       " Row(col='csv-file', count=5),\n",
       " Row(col='sensitivity-analysis', count=23),\n",
       " Row(col='plm', count=13),\n",
       " Row(col='linear', count=7),\n",
       " Row(col='mixed-model', count=832),\n",
       " Row(col='exponential-family', count=41),\n",
       " Row(col='artificial-intelligence', count=23),\n",
       " Row(col='quasi-binomial', count=4),\n",
       " Row(col='kriging', count=4),\n",
       " Row(col='levenes-test', count=23),\n",
       " Row(col='supervised-learning', count=65),\n",
       " Row(col='compositional-data', count=11),\n",
       " Row(col='cosine-distance', count=4),\n",
       " Row(col='lsmeans', count=1),\n",
       " Row(col='marginal-effect', count=5),\n",
       " Row(col='survey', count=346),\n",
       " Row(col='error', count=232),\n",
       " Row(col='econometrics', count=464),\n",
       " Row(col='high-dimensional', count=23),\n",
       " Row(col='largest-value', count=2),\n",
       " Row(col='nnt', count=2),\n",
       " Row(col='estimation', count=865),\n",
       " Row(col='matrix', count=189),\n",
       " Row(col='kruskal-wallis', count=76),\n",
       " Row(col='frailty', count=14),\n",
       " Row(col='fractal', count=6),\n",
       " Row(col='dynamic-regression', count=27),\n",
       " Row(col='probability', count=2055),\n",
       " Row(col='methodology', count=81),\n",
       " Row(col='smoothing', count=103),\n",
       " Row(col='intuition', count=68),\n",
       " Row(col='neyman-pearson-lemma', count=10),\n",
       " Row(col='updating', count=5),\n",
       " Row(col='partial-plot', count=5),\n",
       " Row(col='univariate', count=22),\n",
       " Row(col='minimax', count=2),\n",
       " Row(col='gaussian-process', count=136),\n",
       " Row(col='aic', count=199),\n",
       " Row(col='prediction-interval', count=79),\n",
       " Row(col='suppressor', count=4),\n",
       " Row(col='error-message', count=24),\n",
       " Row(col='ecm', count=5),\n",
       " Row(col='endogeneity', count=29),\n",
       " Row(col='benchmark', count=7),\n",
       " Row(col='exact-test', count=9),\n",
       " Row(col='characteristic-function', count=4),\n",
       " Row(col='cointegration', count=111),\n",
       " Row(col='real-time', count=19),\n",
       " Row(col='weibull', count=56),\n",
       " Row(col='academia', count=9),\n",
       " Row(col='rpart', count=41),\n",
       " Row(col='cochran-mantel-haenszel', count=5),\n",
       " Row(col='referee', count=2),\n",
       " Row(col='rasch', count=8),\n",
       " Row(col='gradient-descent', count=59),\n",
       " Row(col='publication-bias', count=10),\n",
       " Row(col='minimum-variance', count=2),\n",
       " Row(col='synthetic-data', count=12),\n",
       " Row(col='split-plot', count=29),\n",
       " Row(col='iid', count=31),\n",
       " Row(col='record-linkage', count=2),\n",
       " Row(col='pearson', count=122),\n",
       " Row(col='crostons-method', count=6),\n",
       " Row(col='longitudinal', count=124),\n",
       " Row(col='simulation', count=312),\n",
       " Row(col='multiarmed-bandit', count=16),\n",
       " Row(col='ab-test', count=50),\n",
       " Row(col='automatic-algorithms', count=4),\n",
       " Row(col='pmml', count=5),\n",
       " Row(col='mixed-design', count=8),\n",
       " Row(col='random-forest', count=397),\n",
       " Row(col='weighted-regression', count=72),\n",
       " Row(col='blog', count=3),\n",
       " Row(col='exploratory-analysis', count=4),\n",
       " Row(col='abbreviation', count=4),\n",
       " Row(col='dirichlet-process', count=32),\n",
       " Row(col='risk-difference', count=3),\n",
       " Row(col='validation', count=142),\n",
       " Row(col='prior', count=159),\n",
       " Row(col='incidence-rate-ratio', count=14),\n",
       " Row(col='eviews', count=18),\n",
       " Row(col='stata', count=444),\n",
       " Row(col='binomial', count=474),\n",
       " Row(col='parametric', count=83),\n",
       " Row(col='observational-study', count=34),\n",
       " Row(col='laplace-distribution', count=5),\n",
       " Row(col='percentage', count=25),\n",
       " Row(col='saddlepoint-approximation', count=1),\n",
       " Row(col='autocorrelation', count=310),\n",
       " Row(col='belief-propagation', count=1),\n",
       " Row(col='cochran-q', count=3),\n",
       " Row(col='classification', count=1318),\n",
       " Row(col='sample', count=228),\n",
       " Row(col='approximation', count=104),\n",
       " Row(col='segmented-regression', count=12),\n",
       " Row(col='marginal-model', count=2),\n",
       " Row(col='normality', count=184),\n",
       " Row(col='valuation', count=11),\n",
       " Row(col='bradley-terry-model', count=4),\n",
       " Row(col='average-precision', count=12),\n",
       " Row(col='t-distribution', count=65),\n",
       " Row(col='order-statistics', count=79),\n",
       " Row(col='kullback-leibler', count=69),\n",
       " Row(col='signed-rank-test', count=5),\n",
       " Row(col='multicore', count=3),\n",
       " Row(col='mann-whitney-u-test', count=123),\n",
       " Row(col='latent-variable', count=89),\n",
       " Row(col='correspondence-analysis', count=27),\n",
       " Row(col='homogeneity', count=15),\n",
       " Row(col='wilcoxon', count=122),\n",
       " Row(col='partial-correlation', count=39),\n",
       " Row(col='sequence-analysis', count=33),\n",
       " Row(col='hausman', count=27),\n",
       " Row(col='sufficient-statistics', count=29),\n",
       " Row(col='symmetry', count=1),\n",
       " Row(col='protovis', count=1),\n",
       " Row(col='point-estimation', count=31),\n",
       " Row(col='growth-model', count=19),\n",
       " Row(col='cramers-v', count=7),\n",
       " Row(col='ensemble', count=49),\n",
       " Row(col='information-retrieval', count=58),\n",
       " Row(col='abc', count=11),\n",
       " Row(col='polr', count=4),\n",
       " Row(col='t-test', count=679),\n",
       " Row(col='em-algorithm', count=19),\n",
       " Row(col='semi-supervised', count=12),\n",
       " Row(col='apriori', count=4),\n",
       " Row(col='markov-process', count=196),\n",
       " Row(col='point-process', count=46),\n",
       " Row(col='definition', count=56),\n",
       " Row(col='generalized-moments', count=37),\n",
       " Row(col='amos', count=35),\n",
       " Row(col='biomarker', count=1),\n",
       " Row(col='eda', count=57),\n",
       " Row(col='irt', count=51),\n",
       " Row(col='confounding', count=52),\n",
       " Row(col='density-function', count=30),\n",
       " Row(col='performance', count=57),\n",
       " Row(col='blocking', count=21),\n",
       " Row(col='cumulants', count=2),\n",
       " Row(col='theta-method', count=2),\n",
       " Row(col='sas', count=326),\n",
       " Row(col='frequency', count=84),\n",
       " Row(col='hotelling', count=10),\n",
       " Row(col='weighted-data', count=2),\n",
       " Row(col='gamma-distribution', count=162),\n",
       " Row(col='dataframe', count=23),\n",
       " Row(col='microarray', count=30),\n",
       " Row(col='untagged', count=13),\n",
       " Row(col='communication', count=24),\n",
       " Row(col='non-nested', count=9),\n",
       " Row(col='entity-labeling', count=1),\n",
       " Row(col='nonlinear-regression', count=256),\n",
       " Row(col='similarities', count=100),\n",
       " Row(col='anderson-darling', count=18),\n",
       " Row(col='nlp', count=65),\n",
       " Row(col='generalized-least-squares', count=25),\n",
       " Row(col='multilevel-analysis', count=303),\n",
       " Row(col='post-hoc', count=156),\n",
       " Row(col='sums-of-squares', count=63),\n",
       " Row(col='business-intelligence', count=15),\n",
       " Row(col='representative', count=11),\n",
       " Row(col='growth-mixture-model', count=10),\n",
       " Row(col='ergodic', count=6),\n",
       " Row(col='coda', count=2),\n",
       " Row(col='subject-specific', count=2),\n",
       " Row(col='concordance', count=1),\n",
       " Row(col='centering', count=30),\n",
       " Row(col='scores', count=52),\n",
       " Row(col='maximum-entropy', count=36),\n",
       " Row(col='reinforcement-learning', count=25),\n",
       " Row(col='weighted-mean', count=58),\n",
       " Row(col='web', count=21),\n",
       " Row(col='nnet', count=7),\n",
       " Row(col='coverage-probability', count=9),\n",
       " Row(col='conditioning', count=16),\n",
       " Row(col='stochastic-processes', count=238),\n",
       " Row(col='fiducial', count=3),\n",
       " Row(col='link-function', count=32),\n",
       " Row(col='pc-sas', count=2),\n",
       " Row(col='cost-maximization', count=10),\n",
       " Row(col='curve-fitting', count=136),\n",
       " Row(col='boosting', count=95),\n",
       " Row(col='equivalence', count=34),\n",
       " Row(col='binary', count=101),\n",
       " Row(col='offset', count=22),\n",
       " Row(col='gmm', count=1),\n",
       " Row(col='java', count=57),\n",
       " Row(col='standard', count=4),\n",
       " Row(col='topologies', count=3),\n",
       " Row(col='ratio', count=37),\n",
       " Row(col='toeplitz', count=1),\n",
       " Row(col='blue', count=5),\n",
       " Row(col='bayesian', count=1308),\n",
       " Row(col='conjugate-prior', count=45),\n",
       " Row(col='application', count=29),\n",
       " Row(col='data-imputation', count=119),\n",
       " Row(col='continuous', count=4),\n",
       " Row(col='capture-mark-recapture', count=8),\n",
       " Row(col='generalized-eta-squared', count=1),\n",
       " Row(col='r', count=7121),\n",
       " Row(col='interpretation', count=434),\n",
       " Row(col='fraud', count=10),\n",
       " Row(col='presentation', count=13),\n",
       " Row(col='poker', count=1),\n",
       " Row(col='permutation', count=122),\n",
       " Row(col='self-study', count=1762),\n",
       " Row(col='topic-models', count=55),\n",
       " Row(col='probit', count=110),\n",
       " Row(col='parameterization', count=57),\n",
       " Row(col='spectral-analysis', count=25),\n",
       " Row(col='effects', count=18),\n",
       " Row(col='pie-chart', count=10),\n",
       " Row(col='steins-phenomenon', count=8),\n",
       " Row(col='fisher-information', count=30),\n",
       " Row(col='car', count=1),\n",
       " Row(col='explanatory', count=4),\n",
       " Row(col='cross-section', count=42),\n",
       " Row(col='propensity-scores', count=48),\n",
       " Row(col='queueing', count=28),\n",
       " Row(col='eigenvalues', count=56),\n",
       " Row(col='clara', count=1),\n",
       " Row(col='formula', count=4),\n",
       " Row(col='contextual-bandit', count=2),\n",
       " Row(col='standard-error', count=356),\n",
       " Row(col='data-management', count=5),\n",
       " Row(col='signal-detection', count=30),\n",
       " Row(col='beta-distribution', count=57),\n",
       " Row(col='php', count=2),\n",
       " Row(col='nonparametric-regression', count=2),\n",
       " Row(col='wavelet', count=24),\n",
       " Row(col='change-scores', count=23),\n",
       " Row(col='disease', count=6),\n",
       " Row(col='mode', count=28),\n",
       " Row(col='determinant', count=7),\n",
       " Row(col='lifetable', count=4),\n",
       " Row(col='likert', count=216),\n",
       " Row(col='relative-risk', count=31),\n",
       " Row(col='statistical-significance', count=1319),\n",
       " Row(col='cross-validation', count=599),\n",
       " Row(col='independence', count=210),\n",
       " Row(col='log-linear', count=32),\n",
       " Row(col='bayes', count=130),\n",
       " Row(col='functional-data-analysis', count=18),\n",
       " Row(col='estimators', count=81),\n",
       " Row(col='z-statistic', count=28),\n",
       " Row(col='musical-data-analysis', count=6),\n",
       " Row(col='robust-standard-error', count=16),\n",
       " Row(col='gpu', count=4),\n",
       " Row(col='central-limit-theorem', count=128),\n",
       " Row(col='variogram', count=29),\n",
       " Row(col='z-test', count=48),\n",
       " Row(col='information', count=13),\n",
       " Row(col='underdispersion', count=8),\n",
       " Row(col='lilliefors', count=2),\n",
       " Row(col='biostatistics', count=136),\n",
       " Row(col='kolmogorov-smirnov', count=147),\n",
       " Row(col='generalized-linear-model', count=760),\n",
       " Row(col='efficiency', count=24),\n",
       " Row(col='humor', count=4),\n",
       " Row(col='pit', count=1),\n",
       " Row(col='fine-tune', count=1),\n",
       " Row(col='ghyp', count=1),\n",
       " Row(col='meta-analysis', count=183),\n",
       " Row(col='standardization', count=154),\n",
       " Row(col='discriminant-analysis', count=117),\n",
       " Row(col='elastic-net', count=45),\n",
       " Row(col='gui', count=3),\n",
       " Row(col='disaggregation', count=2),\n",
       " Row(col='pls', count=46),\n",
       " Row(col='rule-of-thumb', count=20),\n",
       " Row(col='variational-bayes', count=11),\n",
       " Row(col='lmer', count=258),\n",
       " Row(col='posterior', count=140),\n",
       " Row(col='zipf', count=9),\n",
       " Row(col='mplus', count=16),\n",
       " Row(col='regression-strategies', count=45),\n",
       " Row(col='transportation', count=3),\n",
       " Row(col='optimization', count=402),\n",
       " Row(col='image', count=3),\n",
       " Row(col='multiple-membership', count=2),\n",
       " Row(col='multiple-comparisons', count=424),\n",
       " Row(col='arima', count=386),\n",
       " Row(col='interarrival-time', count=6),\n",
       " Row(col='max-margin', count=3),\n",
       " Row(col='genetics', count=95),\n",
       " Row(col='unsupervised-learning', count=113),\n",
       " Row(col='interactive-visualization', count=16),\n",
       " Row(col='exponential-smoothing', count=48),\n",
       " Row(col='association-rules', count=34),\n",
       " Row(col='back-transformation', count=15),\n",
       " Row(col='belief', count=1),\n",
       " Row(col='differential-equations', count=2),\n",
       " Row(col='mfcc', count=4),\n",
       " Row(col='fitting', count=180),\n",
       " Row(col='glmm', count=143),\n",
       " Row(col='search-theory', count=6),\n",
       " Row(col='data-association', count=8),\n",
       " Row(col='matlab', count=563),\n",
       " Row(col='r-squared', count=184),\n",
       " Row(col='paired-data', count=50),\n",
       " Row(col='vector-fields', count=3),\n",
       " Row(col='scalability', count=1),\n",
       " Row(col='ica', count=16),\n",
       " Row(col='quadratic-form', count=32),\n",
       " Row(col='collecting-data', count=2),\n",
       " Row(col='anova', count=1289),\n",
       " Row(col='python', count=398),\n",
       " Row(col='rejection-sampling', count=18),\n",
       " Row(col='churn', count=12),\n",
       " Row(col='calibration', count=27),\n",
       " Row(col='mgf', count=26),\n",
       " Row(col='blup', count=3),\n",
       " Row(col='convex', count=1),\n",
       " Row(col='residuals', count=283),\n",
       " Row(col='distance', count=136),\n",
       " Row(col='euclidean', count=28),\n",
       " Row(col='mixture', count=127),\n",
       " Row(col='gee', count=103),\n",
       " Row(col='nonparametric-bayes', count=30),\n",
       " ...]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10 = {item.col for item in sorted(counts, key= lambda cnt: cnt['count'], reverse = True)[:10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correlation',\n",
       " 'distributions',\n",
       " 'hypothesis-testing',\n",
       " 'logistic',\n",
       " 'machine-learning',\n",
       " 'probability',\n",
       " 'r',\n",
       " 'regression',\n",
       " 'self-study',\n",
       " 'time-series'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType, StringType, IntegerType, ArrayType, BooleanType\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifintop10(li):\n",
    "    flag = False\n",
    "    for item in li:\n",
    "        if item in top10:\n",
    "            flag = True\n",
    "    return flag\n",
    "\n",
    "ifintop10_udf = udf(ifintop10, BooleanType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_qs = train_df_qs.withColumn('label' , F.when(ifintop10_udf(F.col('Tagwords')), 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+\n",
      "|sum(CASE WHEN (label = 1) THEN 1 ELSE 0 END)|\n",
      "+--------------------------------------------+\n",
      "|                                       22525|\n",
      "+--------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df_qs.agg(cnd_count(F.col('label')==1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol='Body', outputCol='words')\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol='features', numFeatures = 10000)\n",
    "logreg = LogisticRegression(maxIter=100, regParam=0.1)\n",
    "ranfor = RandomForestClassifier(maxDepth=5,numTrees=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.transform(train_df_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashes = hashingTF.transform(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = logreg.fit(hashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_lines.filter(isRow) \\\n",
    "               .filter(lambda line : not isBadXML(line)) \\\n",
    "               .map(line_parser)\\\n",
    "               .toDF(sampleRatio=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_qs = test_df.filter(F.col('PostTypeId')=='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4649"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_qs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokens = tokenizer.transform(test_df_qs)\n",
    "test_hashes = hashingTF.transform(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[AnswerCount: string, Body: string, CommentCount: string, CreationDate: string, Id: string, LastActivityDate: string, OwnerUserId: string, PostTypeId: string, Score: string, Tags: string, Title: string, ViewCount: string, LastEditDate: string, LastEditorUserId: string, ParentId: string, AcceptedAnswerId: string, OwnerDisplayName: string, LastEditorDisplayName: string, words: array<string>, features: vector]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.transform(test_hashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf = test_predictions.withColumn('Id',F.col('Id').cast('int'))\\\n",
    "                        .sort('Id')\\\n",
    "                        .withColumn('prediction',F.col('prediction').cast('int'))\\\n",
    "                        .select(['prediction']).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = list(mydf['prediction'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
